{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of model_engineering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQXMuZZ3nDXb"
      },
      "source": [
        "# Import dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv0mCv0d4R_7"
      },
      "source": [
        "# Standard analytics packages\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.feature_selection import mutual_info_regression, f_regression\n",
        "# Import models\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "# Model evaluation \n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Import model engineering\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Import linear regression models\n",
        "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV\n",
        "# Import Decision Tree models\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXRyn27jnILn"
      },
      "source": [
        "#import csv files\n",
        "#url_allmovie = 'https://raw.githubusercontent.com/JihoonChung/MIE368_project/master/rotten_tomatoes_full.csv'\n",
        "url_allmovie = 'https://raw.githubusercontent.com/JihoonChung/MIE368_project/master/rotten_tomatoes_full_revised.csv'\n",
        "df_rotten_tomatoes_full = pd.read_csv(url_allmovie)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXwB4IEKu3Pq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "0da50860-43d2-43bd-e08c-4f1fb6001f5c"
      },
      "source": [
        "df_rotten_tomatoes_full.head()\n",
        "#df_rotten_tomatoes_full.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>TOMATOMETER score</th>\n",
              "      <th>TOMATOMETER Count</th>\n",
              "      <th>AUDIENCE score</th>\n",
              "      <th>AUDIENCE count</th>\n",
              "      <th>Year</th>\n",
              "      <th>Cast 1</th>\n",
              "      <th>Cast 2</th>\n",
              "      <th>Cast 3</th>\n",
              "      <th>director_name</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Genre_Action</th>\n",
              "      <th>Genre_Art&amp;Foreign</th>\n",
              "      <th>Genre_Classics</th>\n",
              "      <th>Genre_Comedy</th>\n",
              "      <th>Genre_Documentary</th>\n",
              "      <th>Genre_Drama</th>\n",
              "      <th>Genre_Horror</th>\n",
              "      <th>Genre_Kids&amp;Family</th>\n",
              "      <th>Genre_Mystery</th>\n",
              "      <th>Genre_Romance</th>\n",
              "      <th>Genre_SciFi</th>\n",
              "      <th>Rating_G</th>\n",
              "      <th>Rating_NC17</th>\n",
              "      <th>Rating_NR</th>\n",
              "      <th>Rating_PG</th>\n",
              "      <th>Rating_PG-13</th>\n",
              "      <th>Rating_R</th>\n",
              "      <th>cast1_oscar_nom</th>\n",
              "      <th>cast1_oscars</th>\n",
              "      <th>cast2_oscar_nom</th>\n",
              "      <th>cast2_oscars</th>\n",
              "      <th>cast3_oscar_nom</th>\n",
              "      <th>cast3_oscars</th>\n",
              "      <th>cast1_FB_likes</th>\n",
              "      <th>cast2_FB_likes</th>\n",
              "      <th>cast3_FB_likes</th>\n",
              "      <th>dir_oscar_nom</th>\n",
              "      <th>dir_oscars</th>\n",
              "      <th>director_awards</th>\n",
              "      <th>director_facebook_likes</th>\n",
              "      <th>cast_total_facebook_likes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Drive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>13.0</td>\n",
              "      <td>15</td>\n",
              "      <td>2011</td>\n",
              "      <td>Ryan Gosling</td>\n",
              "      <td>Carey Mulligan</td>\n",
              "      <td>Albert Brooks</td>\n",
              "      <td>Nicolas Winding Refn</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33000.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>745.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>34337.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>American Son</td>\n",
              "      <td>50.0</td>\n",
              "      <td>24</td>\n",
              "      <td>47.0</td>\n",
              "      <td>282</td>\n",
              "      <td>2008</td>\n",
              "      <td>Nick Cannon</td>\n",
              "      <td>Melonie Diaz</td>\n",
              "      <td>Matt O'Leary</td>\n",
              "      <td>Neil Abramson</td>\n",
              "      <td>85</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>593.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>303.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Primal</td>\n",
              "      <td>38.0</td>\n",
              "      <td>32</td>\n",
              "      <td>27.0</td>\n",
              "      <td>48</td>\n",
              "      <td>2010</td>\n",
              "      <td>Zoe Tuckwell-Smith</td>\n",
              "      <td>Krew Boylan</td>\n",
              "      <td>Lindsay Farris</td>\n",
              "      <td>Josh Reed</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Kill Team</td>\n",
              "      <td>70.0</td>\n",
              "      <td>47</td>\n",
              "      <td>43.0</td>\n",
              "      <td>63</td>\n",
              "      <td>2014</td>\n",
              "      <td>Adam Winfield</td>\n",
              "      <td>Jeremy Morlock</td>\n",
              "      <td>Andrew Holmes</td>\n",
              "      <td>Dan Krauss</td>\n",
              "      <td>79</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Trick</td>\n",
              "      <td>32.0</td>\n",
              "      <td>25</td>\n",
              "      <td>45.0</td>\n",
              "      <td>51</td>\n",
              "      <td>1999</td>\n",
              "      <td>Christian Campbell</td>\n",
              "      <td>John Paul Pitoc</td>\n",
              "      <td>Tori Spelling</td>\n",
              "      <td>Jim Fall</td>\n",
              "      <td>90</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>396.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Title  ...  cast_total_facebook_likes\n",
              "0          Drive  ...                    34337.0\n",
              "1   American Son  ...                        0.0\n",
              "2         Primal  ...                        0.0\n",
              "3  The Kill Team  ...                        0.0\n",
              "4          Trick  ...                        0.0\n",
              "\n",
              "[5 rows x 42 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl7sLAuH6pQA"
      },
      "source": [
        "# Separate train and test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lCxtLOsvJa2"
      },
      "source": [
        "# one thing is we might have to drop total fb like since now its completely irrelevant. This feature might be introduce in the feature engineering section. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGOqsZS37XT8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "d1f6192e-ced1-46f9-c029-0bbcc8f566f4"
      },
      "source": [
        "column_drop = ['Cast 1','Cast 2','Cast 3','director_name','Title','Year','AUDIENCE score','AUDIENCE count','cast_total_facebook_likes']\n",
        "\n",
        "\n",
        "X = df_rotten_tomatoes_full.drop(columns = column_drop)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X,  # all X data\n",
        "                                                    df_rotten_tomatoes_full['AUDIENCE score'],  # All y data\n",
        "                                                    test_size=0.30,  # Fraction of data in test set\n",
        "                                                    shuffle=True,  # Randomly splits the data\n",
        "                                                    random_state = 3  # Sets random seed for reproducability \n",
        "                                                    )\n",
        "#we can do audience so we can keep Totmatometer score and tomatometer count since critics' score came out first so we can say this is okay as a parameter when we \n",
        "#plan the movie.\n",
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TOMATOMETER score</th>\n",
              "      <th>TOMATOMETER Count</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Genre_Action</th>\n",
              "      <th>Genre_Art&amp;Foreign</th>\n",
              "      <th>Genre_Classics</th>\n",
              "      <th>Genre_Comedy</th>\n",
              "      <th>Genre_Documentary</th>\n",
              "      <th>Genre_Drama</th>\n",
              "      <th>Genre_Horror</th>\n",
              "      <th>Genre_Kids&amp;Family</th>\n",
              "      <th>Genre_Mystery</th>\n",
              "      <th>Genre_Romance</th>\n",
              "      <th>Genre_SciFi</th>\n",
              "      <th>Rating_G</th>\n",
              "      <th>Rating_NC17</th>\n",
              "      <th>Rating_NR</th>\n",
              "      <th>Rating_PG</th>\n",
              "      <th>Rating_PG-13</th>\n",
              "      <th>Rating_R</th>\n",
              "      <th>cast1_oscar_nom</th>\n",
              "      <th>cast1_oscars</th>\n",
              "      <th>cast2_oscar_nom</th>\n",
              "      <th>cast2_oscars</th>\n",
              "      <th>cast3_oscar_nom</th>\n",
              "      <th>cast3_oscars</th>\n",
              "      <th>cast1_FB_likes</th>\n",
              "      <th>cast2_FB_likes</th>\n",
              "      <th>cast3_FB_likes</th>\n",
              "      <th>dir_oscar_nom</th>\n",
              "      <th>dir_oscars</th>\n",
              "      <th>director_awards</th>\n",
              "      <th>director_facebook_likes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>95.0</td>\n",
              "      <td>19</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>488.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>73.0</td>\n",
              "      <td>15</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>92.0</td>\n",
              "      <td>7</td>\n",
              "      <td>104</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1210</th>\n",
              "      <td>40.0</td>\n",
              "      <td>190</td>\n",
              "      <td>120</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>124.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>720</th>\n",
              "      <td>63.0</td>\n",
              "      <td>104</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>338.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>956.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      TOMATOMETER score  ...  director_facebook_likes\n",
              "70                 95.0  ...                    232.0\n",
              "75                 73.0  ...                    232.0\n",
              "889                92.0  ...                    232.0\n",
              "1210               40.0  ...                    124.0\n",
              "720                63.0  ...                    232.0\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKTDtK4Lq_88"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sof2bnfHtUi6"
      },
      "source": [
        "def make_models():\n",
        "  \"\"\"Makes a dictionary of 5 untrained models\"\"\"\n",
        "  #IDK WHAT PARAMETERS TO PUT FOR THE TREES\n",
        "  return {\n",
        "      'LinReg': LinearRegression(),\n",
        "      'LassoCV': LassoCV(),\n",
        "      'RidgeCV': RidgeCV(),\n",
        "      'RF': RandomForestRegressor(),\n",
        "      'CART': DecisionTreeRegressor()\n",
        "  }\n",
        "\n",
        "  #'RF': RandomForestRegressor(max_features=0.2,bootstrap=True,n_estimators=50,random_state=3,max_depth=5)\n",
        "  #'CART': DecisionTreeRegressor(max_features=0.2,random_state=3,max_depth=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wis_cAPqFcka"
      },
      "source": [
        "Create a dataframe to keep track of all the models we train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEahKWWMyCJ6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "979cc1cc-a3ea-4a0f-e0a4-c014c33f3fd1"
      },
      "source": [
        "# Initialize a tuple of names for each model\n",
        "model_names = ('LinReg',  # Linear regression model\n",
        "               'LassoCV',  # Lasso regression model\n",
        "               'RidgeCV',  # Ridge regression model\n",
        "               'RF',  # Random forest classifier \n",
        "               'CART' #Decision tree classifier\n",
        "               )\n",
        "# Initialize a tuple of technique names\n",
        "engineering_techniques = ('Baseline',  # Set of baseline models\n",
        "                          'Scaling',  # Set of models trained with scaled data\n",
        "                          'Feature_Engineering',  # Set of models trained with engineered features\n",
        "                          'Feature_Engineering_overall', # trying\n",
        "                          'Feature_Selection',  # Set of models trained with \"selected\" features\n",
        "                          'Grid_Search',  # Set of models trained via grid search\n",
        "                          'Stacking',  # Set of stacked model \n",
        "                          'Bagging',   # A bagged model\n",
        "                          'Bagging_all',\n",
        "                          'Mutual_Regression (scaled)', # Set of models trained with features from MI using scaled data\n",
        "                          'Mutual_Regression' # Set of models trained with features from MI using normal data\n",
        "                          )\n",
        "\n",
        "# Initialize the multi indices of the `all_models` data frame\n",
        "df_indices = pd.MultiIndex.from_product([model_names, engineering_techniques], names=('model names', 'technique'))\n",
        "# Initialize the `all_models` data frame\n",
        "all_models = pd.DataFrame(index=df_indices, columns=['TrainScore', 'TestScore','Model'])\n",
        "all_models[['TrainScore', 'TestScore']] = all_models[['TrainScore', 'TestScore']].astype(float)\n",
        "all_models  # Initialized data frame only has NaNs, which is perfect!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>TrainScore</th>\n",
              "      <th>TestScore</th>\n",
              "      <th>Model</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model names</th>\n",
              "      <th>technique</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"11\" valign=\"top\">LinReg</th>\n",
              "      <th>Baseline</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Scaling</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Engineering</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Engineering_overall</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Selection</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Grid_Search</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stacking</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bagging</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bagging_all</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mutual_Regression (scaled)</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mutual_Regression</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"11\" valign=\"top\">LassoCV</th>\n",
              "      <th>Baseline</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Scaling</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Engineering</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Engineering_overall</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Selection</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Grid_Search</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stacking</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bagging</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bagging_all</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mutual_Regression (scaled)</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mutual_Regression</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"11\" valign=\"top\">RidgeCV</th>\n",
              "      <th>Baseline</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Scaling</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Engineering</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Engineering_overall</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Selection</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Grid_Search</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stacking</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bagging</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bagging_all</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mutual_Regression (scaled)</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mutual_Regression</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"11\" valign=\"top\">RF</th>\n",
              "      <th>Baseline</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Scaling</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Engineering</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Engineering_overall</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Selection</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Grid_Search</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stacking</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bagging</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bagging_all</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mutual_Regression (scaled)</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mutual_Regression</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"11\" valign=\"top\">CART</th>\n",
              "      <th>Baseline</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Scaling</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Engineering</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Engineering_overall</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Selection</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Grid_Search</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stacking</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bagging</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bagging_all</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mutual_Regression (scaled)</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mutual_Regression</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         TrainScore  TestScore Model\n",
              "model names technique                                               \n",
              "LinReg      Baseline                            NaN        NaN   NaN\n",
              "            Scaling                             NaN        NaN   NaN\n",
              "            Feature_Engineering                 NaN        NaN   NaN\n",
              "            Feature_Engineering_overall         NaN        NaN   NaN\n",
              "            Feature_Selection                   NaN        NaN   NaN\n",
              "            Grid_Search                         NaN        NaN   NaN\n",
              "            Stacking                            NaN        NaN   NaN\n",
              "            Bagging                             NaN        NaN   NaN\n",
              "            Bagging_all                         NaN        NaN   NaN\n",
              "            Mutual_Regression (scaled)          NaN        NaN   NaN\n",
              "            Mutual_Regression                   NaN        NaN   NaN\n",
              "LassoCV     Baseline                            NaN        NaN   NaN\n",
              "            Scaling                             NaN        NaN   NaN\n",
              "            Feature_Engineering                 NaN        NaN   NaN\n",
              "            Feature_Engineering_overall         NaN        NaN   NaN\n",
              "            Feature_Selection                   NaN        NaN   NaN\n",
              "            Grid_Search                         NaN        NaN   NaN\n",
              "            Stacking                            NaN        NaN   NaN\n",
              "            Bagging                             NaN        NaN   NaN\n",
              "            Bagging_all                         NaN        NaN   NaN\n",
              "            Mutual_Regression (scaled)          NaN        NaN   NaN\n",
              "            Mutual_Regression                   NaN        NaN   NaN\n",
              "RidgeCV     Baseline                            NaN        NaN   NaN\n",
              "            Scaling                             NaN        NaN   NaN\n",
              "            Feature_Engineering                 NaN        NaN   NaN\n",
              "            Feature_Engineering_overall         NaN        NaN   NaN\n",
              "            Feature_Selection                   NaN        NaN   NaN\n",
              "            Grid_Search                         NaN        NaN   NaN\n",
              "            Stacking                            NaN        NaN   NaN\n",
              "            Bagging                             NaN        NaN   NaN\n",
              "            Bagging_all                         NaN        NaN   NaN\n",
              "            Mutual_Regression (scaled)          NaN        NaN   NaN\n",
              "            Mutual_Regression                   NaN        NaN   NaN\n",
              "RF          Baseline                            NaN        NaN   NaN\n",
              "            Scaling                             NaN        NaN   NaN\n",
              "            Feature_Engineering                 NaN        NaN   NaN\n",
              "            Feature_Engineering_overall         NaN        NaN   NaN\n",
              "            Feature_Selection                   NaN        NaN   NaN\n",
              "            Grid_Search                         NaN        NaN   NaN\n",
              "            Stacking                            NaN        NaN   NaN\n",
              "            Bagging                             NaN        NaN   NaN\n",
              "            Bagging_all                         NaN        NaN   NaN\n",
              "            Mutual_Regression (scaled)          NaN        NaN   NaN\n",
              "            Mutual_Regression                   NaN        NaN   NaN\n",
              "CART        Baseline                            NaN        NaN   NaN\n",
              "            Scaling                             NaN        NaN   NaN\n",
              "            Feature_Engineering                 NaN        NaN   NaN\n",
              "            Feature_Engineering_overall         NaN        NaN   NaN\n",
              "            Feature_Selection                   NaN        NaN   NaN\n",
              "            Grid_Search                         NaN        NaN   NaN\n",
              "            Stacking                            NaN        NaN   NaN\n",
              "            Bagging                             NaN        NaN   NaN\n",
              "            Bagging_all                         NaN        NaN   NaN\n",
              "            Mutual_Regression (scaled)          NaN        NaN   NaN\n",
              "            Mutual_Regression                   NaN        NaN   NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-bquQgrFUMm"
      },
      "source": [
        "Define a function to fit and score all models and update the all_models dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhU64uun2lWj"
      },
      "source": [
        "def fit_and_score_model(all_models, stage_name, X_train, X_out_of_sample, y_train, y_out_of_sample):\n",
        "    \"\"\"Fits the models that are inialized by models_dict on the X_train and y_train\n",
        "    data, and evalautes the model on the out-of-sample data X_out_of_sample and y_out_of_sample\"\"\"\n",
        "    \n",
        "    # Make a dictionary of models\n",
        "    models_dict = make_models()\n",
        "\n",
        "    # Loop through each model in model_dict\n",
        "    for model_name in models_dict:\n",
        "        model = models_dict[model_name]\n",
        "\n",
        "        # fit the model\n",
        "        model.fit(X_train,y_train)\n",
        "        train_score = model.score(X_train,y_train)\n",
        "        test_score = model.score(X_out_of_sample, y_out_of_sample)\n",
        "\n",
        "\n",
        "        # -------------------------------------------------------------------------\n",
        "        print(f'{model_name} achieved a train score of {train_score:.3f} and test score of {test_score:.3f}')\n",
        "        \n",
        "        all_models.loc[model_name, stage_name] = (train_score, test_score, model)\n",
        "\n",
        "    return all_models\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxk-_uUsFFlB"
      },
      "source": [
        "Define a method to just fit and score a single model and return the train and test score. This can be used if you just want to see performance and do not want to add to all_models just yet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPvgGzfWCXfY"
      },
      "source": [
        "def fit_score_single_model (mdl,mdl_name,X_train, X_out_of_sample, y_train, y_out_of_sample):\n",
        "  # fit the model\n",
        "  mdl.fit(X_train,y_train)\n",
        "  train_score = mdl.score(X_train,y_train)\n",
        "  test_score = mdl.score(X_out_of_sample, y_out_of_sample)\n",
        "  print(f'{mdl_name} achieved a train score of {train_score:.3f} and test score of {test_score:.3f}')\n",
        "  return train_score, test_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y10xaNngFRAA"
      },
      "source": [
        "Define a function to compare model performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEitMK3K-X2Y"
      },
      "source": [
        "def compare_models(technique_name):\n",
        "  \"\"\"Prints out the average and biggest improvement observed between the \n",
        "  models trained with technique_name and the Baseline models\"\"\"\n",
        "\n",
        "  # Evaluate score differences\n",
        "  test_score_differences = (all_models.loc[:, technique_name, :].TestScore - all_models.loc[:, 'Baseline', :].TestScore)\n",
        "\n",
        "  # Get the average and biggest score improvement\n",
        "  mean_score_difference = test_score_differences.mean()\n",
        "  most_score_improvement = test_score_differences.max()\n",
        "\n",
        "  print(f'On average, scores improved by {mean_score_difference:.2f}, and the most improvement was {most_score_improvement:.2f}')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuUe4_TQIcLB"
      },
      "source": [
        "## Model Performance Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-ORA7Q9Id-u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "ba546d18-9957-4f41-f8ff-2f4330211d3e"
      },
      "source": [
        "all_models = fit_and_score_model(all_models, 'Baseline', X_train, X_val, y_train, y_val)\n",
        "all_models.loc[:, 'Baseline', :].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinReg achieved a train score of 0.368 and test score of 0.371\n",
            "LassoCV achieved a train score of 0.339 and test score of 0.349\n",
            "RidgeCV achieved a train score of 0.366 and test score of 0.375\n",
            "RF achieved a train score of 0.903 and test score of 0.340\n",
            "CART achieved a train score of 1.000 and test score of -0.346\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TrainScore</th>\n",
              "      <th>TestScore</th>\n",
              "      <th>Model</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model names</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LinReg</th>\n",
              "      <td>0.367663</td>\n",
              "      <td>0.371280</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LassoCV</th>\n",
              "      <td>0.338874</td>\n",
              "      <td>0.348774</td>\n",
              "      <td>LassoCV(alphas=None, copy_X=True, cv=None, eps...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RidgeCV</th>\n",
              "      <td>0.366021</td>\n",
              "      <td>0.374853</td>\n",
              "      <td>RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>0.902733</td>\n",
              "      <td>0.339792</td>\n",
              "      <td>(DecisionTreeRegressor(ccp_alpha=0.0, criterio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CART</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.346405</td>\n",
              "      <td>DecisionTreeRegressor(ccp_alpha=0.0, criterion...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             TrainScore  ...                                              Model\n",
              "model names              ...                                                   \n",
              "LinReg         0.367663  ...  LinearRegression(copy_X=True, fit_intercept=Tr...\n",
              "LassoCV        0.338874  ...  LassoCV(alphas=None, copy_X=True, cv=None, eps...\n",
              "RidgeCV        0.366021  ...  RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=N...\n",
              "RF             0.902733  ...  (DecisionTreeRegressor(ccp_alpha=0.0, criterio...\n",
              "CART           1.000000  ...  DecisionTreeRegressor(ccp_alpha=0.0, criterion...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkG1Takb5JHJ"
      },
      "source": [
        "# Data Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDsBJJQNFzMv"
      },
      "source": [
        "Define a function to standardize the data. Note: categorigal features should be left alone."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SZSiQgA5MnW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "74851d82-d1ba-493e-db55-af0f3d961c9f"
      },
      "source": [
        "#from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def standardize_data(X_train, X_out_of_sample,y_train,y_out_of_sample):\n",
        "    \"\"\"Standardizes all of the data in X_train and X_out_of_sample. The mean and\n",
        "    standard diviation of each feature (i.e., each column) from the X_train\n",
        "    data is used to standarize both the X_train and X_out_of sample.\"\"\"\n",
        "    X_train_c = X_train.copy()\n",
        "    X_out_of_sample_c = X_out_of_sample.copy()\n",
        "    y_train_c = y_train.copy()\n",
        "    y_out_of_sample_c = y_out_of_sample.copy()\n",
        "\n",
        "\n",
        "    # Initialize data frame for scaled data\n",
        "    df_train_standarized = pd.concat([y_train_c,X_train_c.iloc[:,0:3], X_train_c.iloc[:,21:]],axis =1 ) \n",
        "    df_out_of_sample_standarized = pd.concat([y_out_of_sample_c,X_out_of_sample_c.iloc[:,0:3], X_out_of_sample_c.iloc[:,21:]],axis =1)\n",
        "\n",
        "    # Define scaling function\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Scale the features      \n",
        "    scaler.fit(df_train_standarized)\n",
        "\n",
        "    # Transform the features\n",
        "    train_standarized = scaler.transform(df_train_standarized)\n",
        "    out_of_sample_standarized = scaler.transform(df_out_of_sample_standarized)\n",
        "\n",
        "    # Convert this to dataframe again\n",
        "    train_standarized = pd.DataFrame(train_standarized,columns = df_train_standarized.columns)\n",
        "    out_of_sample_standarized = pd.DataFrame(out_of_sample_standarized,columns = df_out_of_sample_standarized.columns)\n",
        "\n",
        "    X_train_c.reset_index(inplace=True)\n",
        "    X_out_of_sample_c.reset_index(inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "    #split the data and re concat them accordingly since we dont scale binary\n",
        "    X_train_standarized = pd.concat([train_standarized.iloc[:,1:],X_train_c.iloc[:,4:20]],axis = 1)\n",
        "    X_out_of_sample_standarized = pd.concat([out_of_sample_standarized.iloc[:,1:],X_out_of_sample_c.iloc[:,4:20]],axis = 1)\n",
        "\n",
        "    y_train_standarized = train_standarized.iloc[:,0]\n",
        "    y_out_of_sample_standarized = out_of_sample_standarized.iloc[:,0]\n",
        "\n",
        "\n",
        "    return X_train_standarized, X_out_of_sample_standarized,y_train_standarized,y_out_of_sample_standarized, scaler\n",
        "\n",
        "# Make new data that is scaled\"\n",
        "X_train_scaled, X_val_scaled, y_train_scaled,y_val_scaled, scaler = standardize_data(X_train, X_val,y_train,y_val)\n",
        "X_train_scaled.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TOMATOMETER score</th>\n",
              "      <th>TOMATOMETER Count</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>cast1_oscars</th>\n",
              "      <th>cast2_oscar_nom</th>\n",
              "      <th>cast2_oscars</th>\n",
              "      <th>cast3_oscar_nom</th>\n",
              "      <th>cast3_oscars</th>\n",
              "      <th>cast1_FB_likes</th>\n",
              "      <th>cast2_FB_likes</th>\n",
              "      <th>cast3_FB_likes</th>\n",
              "      <th>dir_oscar_nom</th>\n",
              "      <th>dir_oscars</th>\n",
              "      <th>director_awards</th>\n",
              "      <th>director_facebook_likes</th>\n",
              "      <th>Genre_Action</th>\n",
              "      <th>Genre_Art&amp;Foreign</th>\n",
              "      <th>Genre_Classics</th>\n",
              "      <th>Genre_Comedy</th>\n",
              "      <th>Genre_Documentary</th>\n",
              "      <th>Genre_Drama</th>\n",
              "      <th>Genre_Horror</th>\n",
              "      <th>Genre_Kids&amp;Family</th>\n",
              "      <th>Genre_Mystery</th>\n",
              "      <th>Genre_Romance</th>\n",
              "      <th>Genre_SciFi</th>\n",
              "      <th>Rating_G</th>\n",
              "      <th>Rating_NC17</th>\n",
              "      <th>Rating_NR</th>\n",
              "      <th>Rating_PG</th>\n",
              "      <th>Rating_PG-13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.152374</td>\n",
              "      <td>-0.651147</td>\n",
              "      <td>-1.967950</td>\n",
              "      <td>-0.292794</td>\n",
              "      <td>-0.270689</td>\n",
              "      <td>-0.221204</td>\n",
              "      <td>-0.293281</td>\n",
              "      <td>-0.201318</td>\n",
              "      <td>-0.310529</td>\n",
              "      <td>-0.218702</td>\n",
              "      <td>-0.165692</td>\n",
              "      <td>-0.177007</td>\n",
              "      <td>-0.123257</td>\n",
              "      <td>-0.249100</td>\n",
              "      <td>-0.061326</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.385815</td>\n",
              "      <td>-0.691179</td>\n",
              "      <td>-1.904327</td>\n",
              "      <td>-0.292794</td>\n",
              "      <td>-0.270689</td>\n",
              "      <td>-0.221204</td>\n",
              "      <td>-0.293281</td>\n",
              "      <td>-0.201318</td>\n",
              "      <td>-0.332887</td>\n",
              "      <td>-0.218702</td>\n",
              "      <td>-0.165692</td>\n",
              "      <td>-0.177007</td>\n",
              "      <td>-0.123257</td>\n",
              "      <td>-0.249100</td>\n",
              "      <td>-0.061326</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.047843</td>\n",
              "      <td>-0.771243</td>\n",
              "      <td>0.195213</td>\n",
              "      <td>-0.292794</td>\n",
              "      <td>-0.270689</td>\n",
              "      <td>-0.221204</td>\n",
              "      <td>-0.293281</td>\n",
              "      <td>-0.201318</td>\n",
              "      <td>-0.332887</td>\n",
              "      <td>-0.218702</td>\n",
              "      <td>-0.165692</td>\n",
              "      <td>-0.177007</td>\n",
              "      <td>-0.123257</td>\n",
              "      <td>-0.249100</td>\n",
              "      <td>-0.061326</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.764022</td>\n",
              "      <td>1.060220</td>\n",
              "      <td>1.213172</td>\n",
              "      <td>-0.292794</td>\n",
              "      <td>-0.270689</td>\n",
              "      <td>-0.221204</td>\n",
              "      <td>-0.293281</td>\n",
              "      <td>-0.201318</td>\n",
              "      <td>1.077507</td>\n",
              "      <td>1.139184</td>\n",
              "      <td>-0.165692</td>\n",
              "      <td>-0.177007</td>\n",
              "      <td>-0.123257</td>\n",
              "      <td>-0.052622</td>\n",
              "      <td>-0.148024</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.037380</td>\n",
              "      <td>0.199532</td>\n",
              "      <td>-1.204480</td>\n",
              "      <td>-0.292794</td>\n",
              "      <td>-0.270689</td>\n",
              "      <td>-0.221204</td>\n",
              "      <td>-0.293281</td>\n",
              "      <td>-0.201318</td>\n",
              "      <td>-0.338245</td>\n",
              "      <td>-0.218702</td>\n",
              "      <td>0.026479</td>\n",
              "      <td>-0.177007</td>\n",
              "      <td>-0.123257</td>\n",
              "      <td>-0.249100</td>\n",
              "      <td>-0.061326</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TOMATOMETER score  TOMATOMETER Count  ...  Rating_PG  Rating_PG-13\n",
              "0           1.152374          -0.651147  ...          0             0\n",
              "1           0.385815          -0.691179  ...          0             0\n",
              "2           1.047843          -0.771243  ...          0             0\n",
              "3          -0.764022           1.060220  ...          0             1\n",
              "4           0.037380           0.199532  ...          0             0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41o5Ku6EHMTQ"
      },
      "source": [
        "## Model Performance with Scaled Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOJmFbtbE53D"
      },
      "source": [
        "Feed the scaled data into the models. We can't feed continuous y data into CART and RF so lets just score LinReg, LassoCV and Ridge CV."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6xYdmgAviMJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "8a0642f6-cbdc-4d72-ee37-c574e96a02f6"
      },
      "source": [
        "#update all_models with Scaling results\n",
        "all_models = fit_and_score_model(all_models, 'Scaling', X_train_scaled, X_val_scaled, y_train_scaled, y_val_scaled)\n",
        "print('_________________________\\n')\n",
        "compare_models('Scaling')\n",
        "all_models.loc[:, 'Scaling', :].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinReg achieved a train score of 0.367 and test score of 0.369\n",
            "LassoCV achieved a train score of 0.352 and test score of 0.365\n",
            "RidgeCV achieved a train score of 0.366 and test score of 0.368\n",
            "RF achieved a train score of 0.903 and test score of 0.342\n",
            "CART achieved a train score of 1.000 and test score of -0.261\n",
            "_________________________\n",
            "\n",
            "On average, scores improved by 0.02, and the most improvement was 0.09\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TrainScore</th>\n",
              "      <th>TestScore</th>\n",
              "      <th>Model</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model names</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LinReg</th>\n",
              "      <td>0.366933</td>\n",
              "      <td>0.368755</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LassoCV</th>\n",
              "      <td>0.352108</td>\n",
              "      <td>0.365217</td>\n",
              "      <td>LassoCV(alphas=None, copy_X=True, cv=None, eps...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RidgeCV</th>\n",
              "      <td>0.365794</td>\n",
              "      <td>0.367947</td>\n",
              "      <td>RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>0.903476</td>\n",
              "      <td>0.342207</td>\n",
              "      <td>(DecisionTreeRegressor(ccp_alpha=0.0, criterio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CART</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.260768</td>\n",
              "      <td>DecisionTreeRegressor(ccp_alpha=0.0, criterion...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             TrainScore  ...                                              Model\n",
              "model names              ...                                                   \n",
              "LinReg         0.366933  ...  LinearRegression(copy_X=True, fit_intercept=Tr...\n",
              "LassoCV        0.352108  ...  LassoCV(alphas=None, copy_X=True, cv=None, eps...\n",
              "RidgeCV        0.365794  ...  RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=N...\n",
              "RF             0.903476  ...  (DecisionTreeRegressor(ccp_alpha=0.0, criterio...\n",
              "CART           1.000000  ...  DecisionTreeRegressor(ccp_alpha=0.0, criterion...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PlKHW3AnijH"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pdc8CLSE6gdA"
      },
      "source": [
        "## Testing combos -- Don't need to run every time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqtlKAIaP7Mq"
      },
      "source": [
        "https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca9d-QiqEQiq"
      },
      "source": [
        "Vaiance Threshold method for feature slection\n",
        "\n",
        "> Features in which identical value occupies the majority of the samples are said to have zero variance. Such features carrying little information will not affect the target variable and can be dropped. You can adjust the threshold value, default is 0, i.e remove the features that have the same value in all samples. For quasi-constant features, that have the same value for a very large subset, use threshold as 0.01. In other words, drop the column where 99% of the values are similar.[https://towardsdatascience.com/learn-how-to-do-feature-selection-the-right-way-61bca8557bef \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttt9WPycFN5j"
      },
      "source": [
        "Correlation coefficient\n",
        "\n",
        "> Two independent features (X) are highly correlated if they have a strong relationship with each other and move in a similar direction. In that case, you don't need two similar features to be fed to the model, if one can suffice. It centrally takes into consideration the fitted line, slope of the fitted line and the quality of the fit. There are various approaches for calculating correlation coefficients and if a pair of columns cross a certain threshold, the one that shows a high correlation with the target variable (y) will be kept and the other one will be dropped.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-AL26cIFYkq"
      },
      "source": [
        "Mutual Information (for both regression & classification)\n",
        "\n",
        "> The mutual information measures the contribution of a variable towards another variable. In other words, how much will the target variable be impacted if we remove or add the feature? MI is 0 if both the variables are independent and ranges between 0 1 if X is deterministic of Y. MI is primarily the entropy of X, which measures or quantifies the amount of information obtained about one random variable, through the other random variable.\n",
        "The best thing about MI is that it allows one to detect non-linear relationships and works for both regression and classification. Cool! isn't it \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3RBB2gTF3cZ"
      },
      "source": [
        "III. Embedded Methods\n",
        "These methods combine the functionalities of both Filter and Wrapper methods. The upside is that they perform feature selection during the process of training which is why they are called embedded! The computational speed is as good as of filter methods and of course better accuracy, making it a win-win model!\n",
        "\n",
        "\n",
        "> 1.) L1 ( LASSO) Regularization\n",
        "\n",
        "> 2.) Tree Model (for Regression & Classification)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_iqK5lzW1oM"
      },
      "source": [
        "**Transforming Features**\n",
        "\n",
        "> use mutual info regression: Mutual information between two variables, measures how much a given feature can explain another (target), or more technically, how much information about the target will variable will be obtained by having observed a feature.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEgcLD6GgQP3"
      },
      "source": [
        "Try multiplying 2 features with scaled one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlzzdJ_LgP4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "524dd77f-5ea5-40ff-d641-08d92d340ee9"
      },
      "source": [
        "%%capture --no-stdout  \n",
        "\n",
        "mi = mutual_info_regression(X_train_scaled, y_train_scaled)\n",
        "f_test,_ = f_regression(X_train_scaled, y_train_scaled)\n",
        "f_test = np.nan_to_num(f_test)\n",
        "\n",
        "# Iterate through each combination of features\n",
        "for f1_index, f1 in enumerate(X_train_scaled.columns):\n",
        "  for f2_index, f2 in enumerate(X_train_scaled.columns[f1_index + 1:]):\n",
        "    # Multiply the two features to create a new feature\n",
        "    new_feature = X_train_scaled[[f1]].multiply(X_train_scaled[f2], axis=0)\n",
        "\n",
        "    # Evaluate F-value of new feature\n",
        "    mi_new= mutual_info_regression(new_feature, y_train_scaled)\n",
        "    \n",
        "    # Evaluate the relative improvement of the new feature\n",
        "    mi_improvement = mi_new[0]/max(mi[[f1_index, f2_index]])\n",
        "    # Print out features that is sufficiently improved \n",
        "    \n",
        "    if mi_improvement >= 1.5 and mi_new[0] >= 0.05:\n",
        "        '''Note that mi_improvement >= 1.5 and mi_new[0] >= 75 is\n",
        "         relatively arbitrary, and that other values could be used.'''\n",
        "        print(f'{f1} * {f2} has an mi of {mi_new[0]:.2f}')\n",
        "        print(f'\\tBetter by an mi of {mi_improvement:.2f} over features in isolation')\n",
        "\n",
        "        #To see linear or not\n",
        "        f_test_new,_ = f_regression(new_feature, y_train_scaled)\n",
        "\n",
        "        f_test_r = f_test_new[0]/np.max(f_test)\n",
        "\n",
        "        if f_test_r >= 0.9:\n",
        "          print(f\"linearish by {f_test_r:.2f}\\n\")\n",
        "        else:\n",
        "          print(f\" non linearish by {f_test_r:.2f}\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TOMATOMETER Count * cast2_oscars has an mi of 0.05\n",
            "\tBetter by an mi of 2.26 over features in isolation\n",
            " non linearish by 0.00\n",
            "\n",
            "TOMATOMETER Count * cast3_oscars has an mi of 0.07\n",
            "\tBetter by an mi of 3.17 over features in isolation\n",
            " non linearish by 0.00\n",
            "\n",
            "TOMATOMETER Count * cast3_FB_likes has an mi of 0.07\n",
            "\tBetter by an mi of 3.00 over features in isolation\n",
            " non linearish by 0.00\n",
            "\n",
            "TOMATOMETER Count * dir_oscars has an mi of 0.07\n",
            "\tBetter by an mi of 2.89 over features in isolation\n",
            " non linearish by 0.00\n",
            "\n",
            "TOMATOMETER Count * director_facebook_likes has an mi of 0.07\n",
            "\tBetter by an mi of 2.93 over features in isolation\n",
            " non linearish by 0.00\n",
            "\n",
            "Runtime * Rating_NR has an mi of 0.05\n",
            "\tBetter by an mi of inf over features in isolation\n",
            " non linearish by 0.00\n",
            "\n",
            "cast1_FB_likes * Rating_PG-13 has an mi of 0.05\n",
            "\tBetter by an mi of 3.74 over features in isolation\n",
            " non linearish by 0.00\n",
            "\n",
            "dir_oscars * Genre_Drama has an mi of 0.06\n",
            "\tBetter by an mi of 2.87 over features in isolation\n",
            " non linearish by 0.00\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8m8daPGZiPz"
      },
      "source": [
        "Multiply two variables (not scaled)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNfWEgFcXLfD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "outputId": "8d47c274-7017-426a-ba2d-741d09ab77c7"
      },
      "source": [
        "%%capture --no-stdout  \n",
        "\n",
        "mi = mutual_info_regression(X_train, y_train)\n",
        "f_test,_ = f_regression(X_train, y_train)\n",
        "f_test = np.nan_to_num(f_test)\n",
        "\n",
        "# Iterate through each combination of features\n",
        "for f1_index, f1 in enumerate(X_train.columns):\n",
        "  for f2_index, f2 in enumerate(X_train.columns[f1_index + 1:]):\n",
        "    # Multiply the two features to create a new feature\n",
        "    new_feature = X_train[[f1]].multiply(X_train[f2], axis=0)\n",
        "\n",
        "    # Evaluate F-value of new feature\n",
        "    mi_new= mutual_info_regression(new_feature, y_train)\n",
        "    \n",
        "    # Evaluate the relative improvement of the new feature\n",
        "    mi_improvement = mi_new[0]/max(mi[[f1_index, f2_index]])\n",
        "    # Print out features that is sufficiently improved \n",
        "    \n",
        "    if mi_improvement >= 1.5 and mi_new[0] >= 0.05:\n",
        "        '''Note that mi_improvement >= 1.5 and mi_new[0] >= 75 is\n",
        "         relatively arbitrary, and that other values could be used.'''\n",
        "        print(f'{f1} * {f2} has an mi of {mi_new[0]:.2f}')\n",
        "        print(f'\\tBetter by an mi of {mi_improvement:.2f} over features in isolation')\n",
        "\n",
        "        #To see linear or not\n",
        "        f_test_new,_ = f_regression(new_feature, y_train_scaled)\n",
        "\n",
        "        f_test_r = f_test_new[0]/np.max(f_test)\n",
        "\n",
        "        if f_test_r >= 0.9:\n",
        "          print(f\"linearish by {f_test_r:.2f}\\n\")\n",
        "        else:\n",
        "          print(f\" non linearish by {f_test_r:.2f}\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TOMATOMETER Count * Rating_R has an mi of 0.05\n",
            "\tBetter by an mi of 2.49 over features in isolation\n",
            " non linearish by 0.03\n",
            "\n",
            "TOMATOMETER Count * cast2_FB_likes has an mi of 0.06\n",
            "\tBetter by an mi of 1.72 over features in isolation\n",
            " non linearish by 0.00\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-b4176ccd763b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Evaluate F-value of new feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmi_new\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmutual_info_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Evaluate the relative improvement of the new feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36mmutual_info_regression\u001b[0;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    369\u001b[0m     \"\"\"\n\u001b[1;32m    370\u001b[0m     return _estimate_mi(X, y, discrete_features, False, n_neighbors,\n\u001b[0;32m--> 371\u001b[0;31m                         copy, random_state)\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m_estimate_mi\u001b[0;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     mi = [_compute_mi(x, y, discrete_feature, discrete_target, n_neighbors) for\n\u001b[0;32m--> 290\u001b[0;31m           x, discrete_feature in zip(_iterate_columns(X), discrete_mask)]\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     mi = [_compute_mi(x, y, discrete_feature, discrete_target, n_neighbors) for\n\u001b[0;32m--> 290\u001b[0;31m           x, discrete_feature in zip(_iterate_columns(X), discrete_mask)]\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m_compute_mi\u001b[0;34m(x, y, x_discrete, y_discrete, n_neighbors)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compute_mi_cd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compute_mi_cc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m_compute_mi_cc\u001b[0;34m(x, y, n_neighbors)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradius_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mnx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mradius_neighbors\u001b[0;34m(self, X, radius, return_distance, sort_results)\u001b[0m\n\u001b[1;32m    969\u001b[0m                               sort_results=sort_results)\n\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m             )\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh_tF8-MZnyp"
      },
      "source": [
        "Add two vaiables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56b6R9NlZqjh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "046afc60-60b6-4d97-b14f-29cbf5ac7f48"
      },
      "source": [
        "%%capture --no-stdout  \n",
        "# Iterate through each combination of features\n",
        "for f1_index, f1 in enumerate(X_train.columns):\n",
        "  for f2_index, f2 in enumerate(X_train.columns[f1_index + 1:]):\n",
        "    # add the two features to create a new feature\n",
        "    new_feature = X_train[[f1]].add(X_train[[f2]].rename(columns = {X_train[[f2]].columns[0]:X_train[[f1]].columns[0]})) \n",
        "    \n",
        "    # Evaluate F-value of new feature\n",
        "    mi_new= mutual_info_regression(new_feature, y_train)\n",
        "    # Evaluate the relative improvement of the new feature\n",
        "    mi_improvement = mi_new[0]/max(mi[[f1_index, f2_index]])\n",
        "    # Print out features that is sufficiently improved \n",
        "    if mi_improvement >= 1.5 and mi_new[0] >= 0.05:\n",
        "        '''Note that mi_improvement >= 1.5 and mi_new[0] >= 75 is\n",
        "         relatively arbitrary, and that other values could be used.'''\n",
        "        print(f'{f1} + {f2} has an mi of {mi_new[0]:.2f}')\n",
        "        print(f'\\tBetter by an mi of {mi_improvement:.2f} over features in isolation')\n",
        "\n",
        "        #To see linear or not\n",
        "        f_test_new,_ = f_regression(new_feature, y_train)\n",
        "\n",
        "        f_test_r = f_test_new[0]/np.max(f_test)\n",
        "\n",
        "        if f_test_r >= 0.9:\n",
        "          print(f\"linearish by {f_test_r:.2f}\\n\")\n",
        "        else:\n",
        "          print(f\" non linearish by {f_test_r:.2f}\\n\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TOMATOMETER Count + Genre_Drama has an mi of 0.06\n",
            "\tBetter by an mi of 2.88 over features in isolation\n",
            " non linearish by 0.03\n",
            "\n",
            "TOMATOMETER Count + director_facebook_likes has an mi of 0.07\n",
            "\tBetter by an mi of 3.27 over features in isolation\n",
            " non linearish by 0.00\n",
            "\n",
            "Genre_Action + Genre_SciFi has an mi of 0.07\n",
            "\tBetter by an mi of 2.16 over features in isolation\n",
            " non linearish by 0.01\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-b05bbbdb95f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Evaluate F-value of new feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmi_new\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmutual_info_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Evaluate the relative improvement of the new feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmi_improvement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmi_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf1_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36mmutual_info_regression\u001b[0;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    369\u001b[0m     \"\"\"\n\u001b[1;32m    370\u001b[0m     return _estimate_mi(X, y, discrete_features, False, n_neighbors,\n\u001b[0;32m--> 371\u001b[0;31m                         copy, random_state)\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m_estimate_mi\u001b[0;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     mi = [_compute_mi(x, y, discrete_feature, discrete_target, n_neighbors) for\n\u001b[0;32m--> 290\u001b[0;31m           x, discrete_feature in zip(_iterate_columns(X), discrete_mask)]\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     mi = [_compute_mi(x, y, discrete_feature, discrete_target, n_neighbors) for\n\u001b[0;32m--> 290\u001b[0;31m           x, discrete_feature in zip(_iterate_columns(X), discrete_mask)]\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m_compute_mi\u001b[0;34m(x, y, x_discrete, y_discrete, n_neighbors)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compute_mi_cd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compute_mi_cc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m_compute_mi_cc\u001b[0;34m(x, y, n_neighbors)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradius_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mradius_neighbors\u001b[0;34m(self, X, radius, return_distance, sort_results)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind_neighbor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneigh_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mind_neighbor\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m                 \u001b[0mneigh_ind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mind_neighbor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jo0WfNy9PH5y"
      },
      "source": [
        "Sum of squares"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeI4iUN3bVMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e36c720-f3e9-4664-ee00-4ea8742e1491"
      },
      "source": [
        "%%capture --no-stdout  \n",
        "# Iterate through each combination of features\n",
        "for f1_index, f1 in enumerate(X_train.columns):\n",
        "  for f2_index, f2 in enumerate(X_train.columns[f1_index + 1:]):\n",
        "   \n",
        "    X_train_f1_square = X_train[[f1]].pow([2])\n",
        "    X_train_f2_square = X_train[[f2]].pow([2])\n",
        "    new_feature = X_train_f1_square.add(X_train_f2_square.rename(columns = {X_train[[f2]].columns[0]:X_train[[f1]].columns[0]})) \n",
        "    # Evaluate F-value of new feature\n",
        "    mi_new= mutual_info_regression(new_feature, y_train)\n",
        "    # Evaluate the relative improvement of the new feature\n",
        "    mi_improvement = mi_new[0]/max(mi[[f1_index, f2_index]])\n",
        "    # Print out features that is sufficiently improved \n",
        "    if mi_improvement >= 1.5 and mi_new[0] >= 0.05:\n",
        "        '''Note that mi_improvement >= 1.5 and mi_new[0] >= 75 is\n",
        "         relatively arbitrary, and that other values could be used.'''\n",
        "        print(f'{f1} + {f2} has an mi of {mi_new[0]:.2f}')\n",
        "        print(f'\\tBetter by an mi of {mi_improvement:.2f} over features in isolation')\n",
        "\n",
        "        #To see linear or not\n",
        "        f_test_new,_ = f_regression(new_feature, y_train)\n",
        "\n",
        "        f_test_r = f_test_new[0]/np.max(f_test)\n",
        "\n",
        "        if f_test_r >= 0.9:\n",
        "          print(f\"linearish by {f_test_r:.2f}\\n\")\n",
        "        else:\n",
        "          print(f\" non linearish by {f_test_r:.2f}\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TOMATOMETER Count + cast2_FB_likes has an mi of 0.05\n",
            "\tBetter by an mi of 1.57 over features in isolation\n",
            " non linearish by 0.01\n",
            "\n",
            "TOMATOMETER Count + director_awards has an mi of 0.06\n",
            "\tBetter by an mi of 2.81 over features in isolation\n",
            " non linearish by 0.02\n",
            "\n",
            "TOMATOMETER Count + director_facebook_likes has an mi of 0.07\n",
            "\tBetter by an mi of 3.09 over features in isolation\n",
            " non linearish by 0.00\n",
            "\n",
            "Genre_Classics + Genre_SciFi has an mi of 0.05\n",
            "\tBetter by an mi of 10.12 over features in isolation\n",
            " non linearish by 0.00\n",
            "\n",
            "Genre_Romance + Rating_PG-13 has an mi of 0.05\n",
            "\tBetter by an mi of 21.52 over features in isolation\n",
            " non linearish by 0.01\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCH1hNUIbjqo"
      },
      "source": [
        "multiply Three variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUHus8XbbjLc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "26edd08d-9130-45d8-fe9c-5fc1adc51a95"
      },
      "source": [
        "%%capture --no-stdout  \n",
        "# Iterate through each combination of features\n",
        "for f1_index, f1 in enumerate(X_train.columns):\n",
        "  for f2_index, f2 in enumerate(X_train.columns[f1_index + 1:]):\n",
        "    for f3_index, f3 in enumerate(X_train.columns[f1_index + 2:]):\n",
        "      # Multiply the two features to create a new feature\n",
        "      new_feature = X_train[[f1]].multiply(X_train[[f2]].rename(columns = {X_train[[f2]].columns[0]:X_train[[f1]].columns[0]})) \n",
        "      new_feature = new_feature.multiply(X_train[[f3]].rename(columns = {X_train[[f3]].columns[0]:X_train[[f1]].columns[0]}))\n",
        "      # Evaluate F-value of new feature\n",
        "      mi_new= mutual_info_regression(new_feature, y_train)\n",
        "      # Evaluate the relative improvement of the new feature\n",
        "      mi_improvement = mi_new[0]/max(mi[[f1_index, f2_index]])\n",
        "      # Print out features that is sufficiently improved \n",
        "      if mi_improvement >= 1.5 and mi_new[0] >= 0.05:\n",
        "        '''Note that mi_improvement >= 1.5 and mi_new[0] >= 75 is\n",
        "         relatively arbitrary, and that other values could be used.'''\n",
        "        print(f'{f1} + {f2} + {f3} has an mi of {mi_new[0]:.2f}')\n",
        "        print(f'\\tBetter by an mi of {mi_improvement:.2f} over features in isolation')\n",
        "\n",
        "        #To see linear or not\n",
        "        f_test_new,_ = f_regression(new_feature, y_train)\n",
        "\n",
        "        f_test_r = f_test_new[0]/np.max(f_test)\n",
        "\n",
        "        if f_test_r >= 0.9:\n",
        "          print(f\"linearish by {f_test_r:.2f}\\n\")\n",
        "        else:\n",
        "          print(f\" non linearish by {f_test_r:.2f}\\n\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-192def9fdbbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0;31m# Multiply the two features to create a new feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mnew_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       \u001b[0mnew_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m       \u001b[0;31m# Evaluate F-value of new feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mmi_new\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmutual_info_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2867\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_column_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2869\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2870\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2871\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxhm39h9tFkn"
      },
      "source": [
        "Add three var"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlsaDhAktD_A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "8bc09b37-9352-40e3-ce67-e40cc118df96"
      },
      "source": [
        "%%capture --no-stdout  \n",
        "# Iterate through each combination of features\n",
        "for f1_index, f1 in enumerate(X_train.columns):\n",
        "  for f2_index, f2 in enumerate(X_train.columns[f1_index + 1:]):\n",
        "    for f3_index, f3 in enumerate(X_train.columns[f1_index + 2:]):\n",
        "      # Multiply the two features to create a new feature\n",
        "      new_feature = X_train[[f1]].add(X_train[[f2]].rename(columns = {X_train[[f2]].columns[0]:X_train[[f1]].columns[0]})) \n",
        "      new_feature = new_feature.add(X_train[[f3]].rename(columns = {X_train[[f3]].columns[0]:X_train[[f1]].columns[0]}))\n",
        "      # Evaluate F-value of new feature\n",
        "      mi_new= mutual_info_regression(new_feature, y_train)\n",
        "      # Evaluate the relative improvement of the new feature\n",
        "      mi_improvement = mi_new[0]/max(mi[[f1_index, f2_index]])\n",
        "      # Print out features that is sufficiently improved \n",
        "      if mi_improvement >= 1.5 and mi_new[0] >= 0.08:\n",
        "        '''Note that mi_improvement >= 1.5 and mi_new[0] >= 75 is\n",
        "         relatively arbitrary, and that other values could be used.'''\n",
        "        print(f'{f1} + {f2} + {f3} has an mi of {mi_new[0]:.2f}')\n",
        "        print(f'\\tBetter by an mi of {mi_improvement:.2f} over features in isolation')\n",
        "\n",
        "        #To see linear or not\n",
        "        f_test_new,_ = f_regression(new_feature, y_train)\n",
        "\n",
        "        f_test_r = f_test_new[0]/np.max(f_test)\n",
        "\n",
        "        if f_test_r >= 0.9:\n",
        "          print(f\"linearish by {f_test_r:.2f}\\n\")\n",
        "        else:\n",
        "          print(f\" non linearish by {f_test_r:.2f}\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-e2315b31832c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mnew_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0;31m# Evaluate F-value of new feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0mmi_new\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmutual_info_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0;31m# Evaluate the relative improvement of the new feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mmi_improvement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmi_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf1_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36mmutual_info_regression\u001b[0;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    369\u001b[0m     \"\"\"\n\u001b[1;32m    370\u001b[0m     return _estimate_mi(X, y, discrete_features, False, n_neighbors,\n\u001b[0;32m--> 371\u001b[0;31m                         copy, random_state)\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m_estimate_mi\u001b[0;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     mi = [_compute_mi(x, y, discrete_feature, discrete_target, n_neighbors) for\n\u001b[0;32m--> 290\u001b[0;31m           x, discrete_feature in zip(_iterate_columns(X), discrete_mask)]\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     mi = [_compute_mi(x, y, discrete_feature, discrete_target, n_neighbors) for\n\u001b[0;32m--> 290\u001b[0;31m           x, discrete_feature in zip(_iterate_columns(X), discrete_mask)]\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m_compute_mi\u001b[0;34m(x, y, x_discrete, y_discrete, n_neighbors)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compute_mi_cd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compute_mi_cc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m_compute_mi_cc\u001b[0;34m(x, y, n_neighbors)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mnx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradius_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1162\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'precomputed'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \"\"\"\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    455\u001b[0m             self._tree = KDTree(X, self.leaf_size,\n\u001b[1;32m    456\u001b[0m                                 \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m                                 **self.effective_metric_params_)\n\u001b[0m\u001b[1;32m    458\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'brute'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_a_3R0jtaro"
      },
      "source": [
        "Add three scaled variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGS7pbGJtaPU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "10723d77-5ac3-418a-ccc9-1a6ac5ab21e5"
      },
      "source": [
        "%%capture --no-stdout    \n",
        "\n",
        "mi = mutual_info_regression(X_train_scaled, y_train_scaled)\n",
        "f_test,_ = f_regression(X_train_scaled, y_train_scaled)\n",
        "f_test = np.nan_to_num(f_test)\n",
        "\n",
        "# Iterate through each combination of features\n",
        "for f1_index, f1 in enumerate(X_train_scaled.columns):\n",
        "  for f2_index, f2 in enumerate(X_train_scaled.columns[f1_index + 1:]):\n",
        "    for f3_index, f3 in enumerate(X_train_scaled.columns[f1_index + 2:]):\n",
        "        # Multiply the two features to create a new feature\n",
        "        new_feature = X_train_scaled[[f1]].add(X_train_scaled[[f2]].rename(columns = {X_train_scaled[[f2]].columns[0]:X_train_scaled[[f1]].columns[0]})) \n",
        "        new_feature = new_feature.add(X_train_scaled[[f3]].rename(columns = {X_train_scaled[[f3]].columns[0]:X_train_scaled[[f1]].columns[0]}))\n",
        "        \n",
        "        # Evaluate F-value of new feature\n",
        "        mi_new= mutual_info_regression(new_feature, y_train_scaled)\n",
        "        # Evaluate the relative improvement of the new feature\n",
        "        mi_improvement = mi_new[0]/max(mi[[f1_index, f2_index]])\n",
        "        # Print out features that is sufficiently improved \n",
        "        if mi_improvement >= 1.5 and mi_new[0] >= 0.10:\n",
        "          '''Note that mi_improvement >= 1.5 and mi_new[0] >= 75 is\n",
        "          relatively arbitrary, and that other values could be used.'''\n",
        "          print(f'{f1} + {f2} + {f3}  has an mi of {mi_new[0]:.2f}')\n",
        "          print(f'\\tBetter by an mi of {mi_improvement:.2f} over features in isolation')\n",
        "\n",
        "          #To see linear or not\n",
        "          f_test_new,_ = f_regression(new_feature, y_train_scaled)\n",
        "\n",
        "          f_test_r = f_test_new[0]/np.max(f_test)\n",
        "\n",
        "          if f_test_r >= 0.9:\n",
        "            print(f\"linearish by {f_test_r:.2f}\\n\")\n",
        "          else:\n",
        "            print(f\" non linearish by {f_test_r:.2f}\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-e968466add8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutual_info_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mf_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36mmutual_info_regression\u001b[0;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    369\u001b[0m     \"\"\"\n\u001b[1;32m    370\u001b[0m     return _estimate_mi(X, y, discrete_features, False, n_neighbors,\n\u001b[0;32m--> 371\u001b[0;31m                         copy, random_state)\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m_estimate_mi\u001b[0;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     mi = [_compute_mi(x, y, discrete_feature, discrete_target, n_neighbors) for\n\u001b[0;32m--> 290\u001b[0;31m           x, discrete_feature in zip(_iterate_columns(X), discrete_mask)]\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     mi = [_compute_mi(x, y, discrete_feature, discrete_target, n_neighbors) for\n\u001b[0;32m--> 290\u001b[0;31m           x, discrete_feature in zip(_iterate_columns(X), discrete_mask)]\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m_compute_mi\u001b[0;34m(x, y, x_discrete, y_discrete, n_neighbors)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compute_mi_cd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compute_mi_cc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGfzUxFiHdZ_"
      },
      "source": [
        "# New Feature Combos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mvp1WFYu60W"
      },
      "source": [
        "I think i have to try different combintation of these feature and also i have to fix Total Fb likes since that has been a didfferent column now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhJbh_qOJPoJ"
      },
      "source": [
        "# get number of genre colummn, total number of cast oscar, total number of director and cast likes, \n",
        "def new_feature_combos(X,condition):\n",
        "   \n",
        "    # First, we apply the monotone transform function\n",
        "    X_new = X.copy()\n",
        "    \n",
        "    # Then we add new features\n",
        "    enters_genre = True\n",
        "    enters_oscar = True\n",
        "    enters_FB = True\n",
        "    enters_award =True\n",
        "\n",
        "    for f_index, f in enumerate(X_new.columns):\n",
        "      if  'Genre' in f:\n",
        "        if enters_genre:\n",
        "          new_feature_genre = X_new[[f]].rename(columns = {X_new[[f]].columns[0]:\"total_genre\"})\n",
        "          enters_genre = False\n",
        "        else:\n",
        "          new_feature_genre = new_feature_genre.add(X_new[[f]].rename(columns = {X_new[[f]].columns[0]:\"total_genre\"})) \n",
        "\n",
        "      elif 'oscar_nom' in f:\n",
        "        if enters_oscar:\n",
        "          new_feature_oscar_nom = X_new[[f]].rename(columns = {X_new[[f]].columns[0]:\"total_oscar_nom\"})\n",
        "          enters_oscar = False\n",
        "        else:\n",
        "          new_feature_oscar_nom = new_feature_oscar_nom.add(X_new[[f]].rename(columns = {X_new[[f]].columns[0]:\"total_oscar_nom\"})) \n",
        "\n",
        "      \n",
        "      elif 'FB_likes' in f:\n",
        "         if enters_FB:\n",
        "          new_feature_FB = X_new[[f]].rename(columns = {X_new[[f]].columns[0]:\"total_cast_facebook_likes\"})\n",
        "          enters_FB = False\n",
        "         else:\n",
        "          new_feature_FB = new_feature_FB.add(X_new[[f]].rename(columns = {X_new[[f]].columns[0]:\"total_cast_facebook_likes\"})) \n",
        "\n",
        "\n",
        "      elif 'oscars' in f or 'awards' in f:\n",
        "        if enters_award:\n",
        "          new_feature_awards = X_new[[f]].rename(columns = {X_new[[f]].columns[0]:\"total_awards\"})\n",
        "          enters_award = False\n",
        "        else:\n",
        "          new_feature_awards = new_feature_awards.add(X_new[[f]].rename(columns = {X_new[[f]].columns[0]:\"total_awards\"})) \n",
        "\n",
        "\n",
        "    #X_new['total_genre'] = new_feature_genre\n",
        "    #X_new['total_oscar_nom'] = new_feature_oscar_nom\n",
        "    #X_new['Total_FB'] = new_feature_FB\n",
        "    #X_new['total_awards'] = new_feature_awards\n",
        "    # im gonna use this to see\n",
        "    #X_new['Runtime + Genre_Horror + Rating_PG-13'] = X_new.Runtime + X_new.Genre_Horror + X_new.Rating_PG-13\n",
        "\n",
        "    if condition == 'max':\n",
        "      X_new['Genre_Horror + Rating_G + Rating_NR'] = X_new.Rating_G + X_new.Genre_Horror + X_new.Rating_NR\n",
        "    elif condition == 'overall':\n",
        "      X_new['Genre_Horror + Rating_G + Rating_NR'] = X_new.Rating_G + X_new.Genre_Horror + X_new.Rating_NR\n",
        "      X_new['total_cast_facebook_likes'] = new_feature_FB\n",
        "\n",
        "\n",
        "\n",
        "    #tried lot of combo this one was the best one\n",
        "    #X_new['Genre_Horror + Rating_G + Rating_NR'] = X_new.Rating_G + X_new.Genre_Horror + X_new.Rating_NR\n",
        "\n",
        "    return X_new\n",
        "\n",
        "# Make new X features with interactions\n",
        "X_train_interactions = new_feature_combos(X_train,'max')\n",
        "X_val_interactions = new_feature_combos(X_val,'max')\n",
        "\n",
        "X_train_interactions_scaled = new_feature_combos(X_train_scaled,'max')\n",
        "X_val_interactions_scaled = new_feature_combos(X_val_scaled,'max')\n",
        "\n",
        "\n",
        "X_train_interactions_overall = new_feature_combos(X_train, 'overall')\n",
        "X_val_interactions_overall = new_feature_combos(X_val,'overall')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwV1o3_AHhmB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "be0c0da3-fe20-4cd1-ddb7-2cb43404a3e0"
      },
      "source": [
        "#investigate the negative training score....\n",
        "all_models = fit_and_score_model(all_models, 'Feature_Engineering', X_train_interactions, X_val_interactions, y_train, y_val)\n",
        "\n",
        "print('_________________________\\n')\n",
        "compare_models('Feature_Engineering')\n",
        "all_models.loc[:, 'Feature_Engineering', :].head()\n",
        "\n",
        "\n",
        "#investigate the negative training score....\n",
        "all_models = fit_and_score_model(all_models, 'Feature_Engineering_overall', X_train_interactions_overall, X_val_interactions_overall, y_train, y_val)\n",
        "\n",
        "print('_________________________\\n')\n",
        "compare_models('Feature_Engineering_overall')\n",
        "all_models.loc[:, 'Feature_Engineering_overall', :].head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinReg achieved a train score of 0.368 and test score of 0.371\n",
            "LassoCV achieved a train score of 0.339 and test score of 0.349\n",
            "RidgeCV achieved a train score of 0.366 and test score of 0.376\n",
            "RF achieved a train score of 0.901 and test score of 0.350\n",
            "CART achieved a train score of 1.000 and test score of -0.318\n",
            "_________________________\n",
            "\n",
            "On average, scores improved by 0.01, and the most improvement was 0.03\n",
            "LinReg achieved a train score of 0.368 and test score of 0.371\n",
            "LassoCV achieved a train score of 0.339 and test score of 0.349\n",
            "RidgeCV achieved a train score of 0.366 and test score of 0.376\n",
            "RF achieved a train score of 0.902 and test score of 0.341\n",
            "CART achieved a train score of 1.000 and test score of -0.187\n",
            "_________________________\n",
            "\n",
            "On average, scores improved by 0.03, and the most improvement was 0.16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TrainScore</th>\n",
              "      <th>TestScore</th>\n",
              "      <th>Model</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model names</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LinReg</th>\n",
              "      <td>0.367663</td>\n",
              "      <td>0.371158</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LassoCV</th>\n",
              "      <td>0.338932</td>\n",
              "      <td>0.348813</td>\n",
              "      <td>LassoCV(alphas=None, copy_X=True, cv=None, eps...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RidgeCV</th>\n",
              "      <td>0.366076</td>\n",
              "      <td>0.375641</td>\n",
              "      <td>RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>0.902333</td>\n",
              "      <td>0.340646</td>\n",
              "      <td>(DecisionTreeRegressor(ccp_alpha=0.0, criterio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CART</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.187439</td>\n",
              "      <td>DecisionTreeRegressor(ccp_alpha=0.0, criterion...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             TrainScore  ...                                              Model\n",
              "model names              ...                                                   \n",
              "LinReg         0.367663  ...  LinearRegression(copy_X=True, fit_intercept=Tr...\n",
              "LassoCV        0.338932  ...  LassoCV(alphas=None, copy_X=True, cv=None, eps...\n",
              "RidgeCV        0.366076  ...  RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=N...\n",
              "RF             0.902333  ...  (DecisionTreeRegressor(ccp_alpha=0.0, criterio...\n",
              "CART           1.000000  ...  DecisionTreeRegressor(ccp_alpha=0.0, criterion...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl-QonkfMMz7"
      },
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdsU6Fd_aohI"
      },
      "source": [
        "## **Features selected from VarianceThreshold**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7-t58ljXAax",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "outputId": "010e1c6f-93df-442d-eada-2e05cb21bec2"
      },
      "source": [
        "#Variance Threshold with X_train_interactions\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "print(X_train_interactions.shape)     #output (143, 59)\n",
        "var_filter = VarianceThreshold(threshold = 0.05)  \n",
        "train = var_filter.fit_transform(X_train_interactions)\n",
        "\n",
        "#to get the count of features that are not constant\n",
        "\n",
        "print(train.shape)   # output (143, 56)       \n",
        "#or\n",
        "print(len(X_train_interactions.columns[var_filter.get_support()]))  #output 56\n",
        "\n",
        "print(X_train_interactions.columns[var_filter.get_support()])\n",
        "print(var_filter.get_support())\n",
        "#rating G and Rating_NC17 got removed for threshold 0.01\n",
        "#threshold 0.05 classics, genre documentary got deleted\n",
        "\n",
        "selected = X_train_interactions.columns[var_filter.get_support()]\n",
        "X_train_selected = X_train_interactions[selected]\n",
        "X_val_selected = X_val_interactions[selected]\n",
        "\n",
        "X_train_selected.shape\n",
        "X_val_selected\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(893, 34)\n",
            "(893, 28)\n",
            "28\n",
            "Index(['TOMATOMETER score', 'TOMATOMETER Count', 'Runtime', 'Genre_Action',\n",
            "       'Genre_Art&Foreign', 'Genre_Comedy', 'Genre_Documentary', 'Genre_Drama',\n",
            "       'Genre_Horror', 'Genre_Mystery', 'Genre_Romance', 'Genre_SciFi',\n",
            "       'Rating_NR', 'Rating_PG', 'Rating_PG-13', 'Rating_R', 'cast1_oscar_nom',\n",
            "       'cast1_oscars', 'cast2_oscar_nom', 'cast2_oscars', 'cast3_oscar_nom',\n",
            "       'cast1_FB_likes', 'cast2_FB_likes', 'cast3_FB_likes', 'dir_oscar_nom',\n",
            "       'director_awards', 'director_facebook_likes',\n",
            "       'Genre_Horror + Rating_G + Rating_NR'],\n",
            "      dtype='object')\n",
            "[ True  True  True  True  True False  True  True  True  True False  True\n",
            "  True  True False False  True  True  True  True  True  True  True  True\n",
            "  True False  True  True  True  True False  True  True  True]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TOMATOMETER score</th>\n",
              "      <th>TOMATOMETER Count</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Genre_Action</th>\n",
              "      <th>Genre_Art&amp;Foreign</th>\n",
              "      <th>Genre_Comedy</th>\n",
              "      <th>Genre_Documentary</th>\n",
              "      <th>Genre_Drama</th>\n",
              "      <th>Genre_Horror</th>\n",
              "      <th>Genre_Mystery</th>\n",
              "      <th>Genre_Romance</th>\n",
              "      <th>Genre_SciFi</th>\n",
              "      <th>Rating_NR</th>\n",
              "      <th>Rating_PG</th>\n",
              "      <th>Rating_PG-13</th>\n",
              "      <th>Rating_R</th>\n",
              "      <th>cast1_oscar_nom</th>\n",
              "      <th>cast1_oscars</th>\n",
              "      <th>cast2_oscar_nom</th>\n",
              "      <th>cast2_oscars</th>\n",
              "      <th>cast3_oscar_nom</th>\n",
              "      <th>cast1_FB_likes</th>\n",
              "      <th>cast2_FB_likes</th>\n",
              "      <th>cast3_FB_likes</th>\n",
              "      <th>dir_oscar_nom</th>\n",
              "      <th>director_awards</th>\n",
              "      <th>director_facebook_likes</th>\n",
              "      <th>Genre_Horror + Rating_G + Rating_NR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>573</th>\n",
              "      <td>90.0</td>\n",
              "      <td>41</td>\n",
              "      <td>101</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>611.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>752</th>\n",
              "      <td>45.0</td>\n",
              "      <td>100</td>\n",
              "      <td>106</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14000.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>545.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>948</th>\n",
              "      <td>59.0</td>\n",
              "      <td>14</td>\n",
              "      <td>90</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>404.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1011</th>\n",
              "      <td>47.0</td>\n",
              "      <td>7</td>\n",
              "      <td>92</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>886.0</td>\n",
              "      <td>827.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1136</th>\n",
              "      <td>88.0</td>\n",
              "      <td>7</td>\n",
              "      <td>88</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>27.0</td>\n",
              "      <td>84</td>\n",
              "      <td>109</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>18000.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1091</th>\n",
              "      <td>84.0</td>\n",
              "      <td>179</td>\n",
              "      <td>127</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736</th>\n",
              "      <td>58.0</td>\n",
              "      <td>268</td>\n",
              "      <td>122</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18000.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>68.0</td>\n",
              "      <td>44</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>651.0</td>\n",
              "      <td>595.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1200</th>\n",
              "      <td>56.0</td>\n",
              "      <td>54</td>\n",
              "      <td>111</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>384 rows  28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      TOMATOMETER score  ...  Genre_Horror + Rating_G + Rating_NR\n",
              "573                90.0  ...                                    1\n",
              "752                45.0  ...                                    1\n",
              "948                59.0  ...                                    1\n",
              "1011               47.0  ...                                    0\n",
              "1136               88.0  ...                                    1\n",
              "...                 ...  ...                                  ...\n",
              "464                27.0  ...                                    0\n",
              "1091               84.0  ...                                    0\n",
              "736                58.0  ...                                    0\n",
              "178                68.0  ...                                    2\n",
              "1200               56.0  ...                                    1\n",
              "\n",
              "[384 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "id": "cX3w3st3oKnp",
        "outputId": "8b843aee-462c-4cc0-d853-23358cc5a0e2"
      },
      "source": [
        "#Variance Threshold with X_train\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "print(X_train_interactions.shape)     #output (143, 59)\n",
        "var_filter = VarianceThreshold(threshold = 0.05)  \n",
        "train = var_filter.fit_transform(X_train_interactions)\n",
        "\n",
        "print(train.shape)        \n",
        "#or\n",
        "print(len(X_train_interactions.columns[var_filter.get_support()])) \n",
        "\n",
        "print(X_train_interactions.columns[var_filter.get_support()])\n",
        "print(var_filter.get_support())\n",
        "\n",
        "selected = X_train_interactions.columns[var_filter.get_support()]\n",
        "X_train_selected = X_train_interactions[selected]\n",
        "X_val_selected = X_val_interactions[selected]\n",
        "\n",
        "X_train_selected.shape\n",
        "X_val_selected"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(893, 34)\n",
            "(893, 28)\n",
            "28\n",
            "Index(['TOMATOMETER score', 'TOMATOMETER Count', 'Runtime', 'Genre_Action',\n",
            "       'Genre_Art&Foreign', 'Genre_Comedy', 'Genre_Documentary', 'Genre_Drama',\n",
            "       'Genre_Horror', 'Genre_Mystery', 'Genre_Romance', 'Genre_SciFi',\n",
            "       'Rating_NR', 'Rating_PG', 'Rating_PG-13', 'Rating_R', 'cast1_oscar_nom',\n",
            "       'cast1_oscars', 'cast2_oscar_nom', 'cast2_oscars', 'cast3_oscar_nom',\n",
            "       'cast1_FB_likes', 'cast2_FB_likes', 'cast3_FB_likes', 'dir_oscar_nom',\n",
            "       'director_awards', 'director_facebook_likes',\n",
            "       'Genre_Horror + Rating_G + Rating_NR'],\n",
            "      dtype='object')\n",
            "[ True  True  True  True  True False  True  True  True  True False  True\n",
            "  True  True False False  True  True  True  True  True  True  True  True\n",
            "  True False  True  True  True  True False  True  True  True]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TOMATOMETER score</th>\n",
              "      <th>TOMATOMETER Count</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Genre_Action</th>\n",
              "      <th>Genre_Art&amp;Foreign</th>\n",
              "      <th>Genre_Comedy</th>\n",
              "      <th>Genre_Documentary</th>\n",
              "      <th>Genre_Drama</th>\n",
              "      <th>Genre_Horror</th>\n",
              "      <th>Genre_Mystery</th>\n",
              "      <th>Genre_Romance</th>\n",
              "      <th>Genre_SciFi</th>\n",
              "      <th>Rating_NR</th>\n",
              "      <th>Rating_PG</th>\n",
              "      <th>Rating_PG-13</th>\n",
              "      <th>Rating_R</th>\n",
              "      <th>cast1_oscar_nom</th>\n",
              "      <th>cast1_oscars</th>\n",
              "      <th>cast2_oscar_nom</th>\n",
              "      <th>cast2_oscars</th>\n",
              "      <th>cast3_oscar_nom</th>\n",
              "      <th>cast1_FB_likes</th>\n",
              "      <th>cast2_FB_likes</th>\n",
              "      <th>cast3_FB_likes</th>\n",
              "      <th>dir_oscar_nom</th>\n",
              "      <th>director_awards</th>\n",
              "      <th>director_facebook_likes</th>\n",
              "      <th>Genre_Horror + Rating_G + Rating_NR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>573</th>\n",
              "      <td>90.0</td>\n",
              "      <td>41</td>\n",
              "      <td>101</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>611.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>752</th>\n",
              "      <td>45.0</td>\n",
              "      <td>100</td>\n",
              "      <td>106</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14000.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>545.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>948</th>\n",
              "      <td>59.0</td>\n",
              "      <td>14</td>\n",
              "      <td>90</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>404.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1011</th>\n",
              "      <td>47.0</td>\n",
              "      <td>7</td>\n",
              "      <td>92</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>886.0</td>\n",
              "      <td>827.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1136</th>\n",
              "      <td>88.0</td>\n",
              "      <td>7</td>\n",
              "      <td>88</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>27.0</td>\n",
              "      <td>84</td>\n",
              "      <td>109</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>18000.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1091</th>\n",
              "      <td>84.0</td>\n",
              "      <td>179</td>\n",
              "      <td>127</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736</th>\n",
              "      <td>58.0</td>\n",
              "      <td>268</td>\n",
              "      <td>122</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18000.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>68.0</td>\n",
              "      <td>44</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>651.0</td>\n",
              "      <td>595.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1200</th>\n",
              "      <td>56.0</td>\n",
              "      <td>54</td>\n",
              "      <td>111</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>384 rows  28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      TOMATOMETER score  ...  Genre_Horror + Rating_G + Rating_NR\n",
              "573                90.0  ...                                    1\n",
              "752                45.0  ...                                    1\n",
              "948                59.0  ...                                    1\n",
              "1011               47.0  ...                                    0\n",
              "1136               88.0  ...                                    1\n",
              "...                 ...  ...                                  ...\n",
              "464                27.0  ...                                    0\n",
              "1091               84.0  ...                                    0\n",
              "736                58.0  ...                                    0\n",
              "178                68.0  ...                                    2\n",
              "1200               56.0  ...                                    1\n",
              "\n",
              "[384 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CuKj8epoK5b"
      },
      "source": [
        "## Model Performance with Selected Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "FIMDhRDQoK5c",
        "outputId": "78497f3c-614d-4ab5-d95b-226aa8e11fe6"
      },
      "source": [
        "#using columns from variance threshold with X_train_interactions\n",
        "#gives same results as with normal X_train \n",
        "all_models = fit_and_score_model(all_models, 'Feature_Selection', X_train_selected, X_val_selected, y_train, y_val)\n",
        "\n",
        "\n",
        "print('_________________________\\n')\n",
        "compare_models('Feature_Selection')\n",
        "all_models.loc[:, 'Feature_Selection', :].head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinReg achieved a train score of 0.364 and test score of 0.367\n",
            "LassoCV achieved a train score of 0.339 and test score of 0.349\n",
            "RidgeCV achieved a train score of 0.363 and test score of 0.373\n",
            "RF achieved a train score of 0.901 and test score of 0.342\n",
            "CART achieved a train score of 1.000 and test score of -0.423\n",
            "_________________________\n",
            "\n",
            "On average, scores improved by -0.02, and the most improvement was 0.00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TrainScore</th>\n",
              "      <th>TestScore</th>\n",
              "      <th>Model</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model names</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LinReg</th>\n",
              "      <td>0.364208</td>\n",
              "      <td>0.367059</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LassoCV</th>\n",
              "      <td>0.338874</td>\n",
              "      <td>0.348774</td>\n",
              "      <td>LassoCV(alphas=None, copy_X=True, cv=None, eps...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RidgeCV</th>\n",
              "      <td>0.363367</td>\n",
              "      <td>0.373276</td>\n",
              "      <td>RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>0.901064</td>\n",
              "      <td>0.342019</td>\n",
              "      <td>(DecisionTreeRegressor(ccp_alpha=0.0, criterio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CART</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.423230</td>\n",
              "      <td>DecisionTreeRegressor(ccp_alpha=0.0, criterion...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             TrainScore  ...                                              Model\n",
              "model names              ...                                                   \n",
              "LinReg         0.364208  ...  LinearRegression(copy_X=True, fit_intercept=Tr...\n",
              "LassoCV        0.338874  ...  LassoCV(alphas=None, copy_X=True, cv=None, eps...\n",
              "RidgeCV        0.363367  ...  RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=N...\n",
              "RF             0.901064  ...  (DecisionTreeRegressor(ccp_alpha=0.0, criterio...\n",
              "CART           1.000000  ...  DecisionTreeRegressor(ccp_alpha=0.0, criterion...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhYUaJqtau7F"
      },
      "source": [
        "## **Mutual_info_regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBmox3fxtmZl"
      },
      "source": [
        "from X_train_interactions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYEjATcNZOFv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c92aea7-a58b-45ea-8a42-4ddf09c8bab0"
      },
      "source": [
        "from sklearn.feature_selection import mutual_info_regression  \n",
        "from sklearn.feature_selection import SelectKBest\n",
        "\n",
        "selector = SelectKBest(mutual_info_regression, k=10)\n",
        "X_train_new = selector.fit_transform(X_train_interactions, y_train)  #Applying transformation to the training set\n",
        "#to get names of the selected features\n",
        "mask = selector.get_support()     # Output   array([False, False,  True,  True,  True, False ....])\n",
        "\n",
        "#should we also do X_val_new??\n",
        "\n",
        "\n",
        "print(selector.scores_)    \n",
        "\n",
        "new_features = X_train_interactions.columns[mask]\n",
        " \n",
        "print(new_features)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.18067283 0.01053829 0.         0.0242431  0.         0.\n",
            " 0.         0.         0.0062688  0.00884917 0.         0.01729227\n",
            " 0.01138817 0.00268103 0.00797505 0.         0.01946982 0.\n",
            " 0.01409826 0.         0.         0.         0.01476268 0.02468243\n",
            " 0.         0.00635557 0.         0.01748266 0.         0.\n",
            " 0.         0.         0.02497346 0.03610573]\n",
            "Index(['TOMATOMETER score', 'Genre_Action', 'Genre_Mystery', 'Rating_NR',\n",
            "       'Rating_PG-13', 'cast2_oscar_nom', 'cast2_oscars', 'cast2_FB_likes',\n",
            "       'director_facebook_likes', 'Genre_Horror + Rating_G + Rating_NR'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHFJG5PkstMr"
      },
      "source": [
        "X_train_interactions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hMcHghOvBiw"
      },
      "source": [
        "select_features = SelectKBest(mutual_info_regression, k=10)\n",
        "select_features = select_features.fit(X_train_interactions, y_train)\n",
        "\n",
        "# Get mask of columns that have good features\n",
        "feature_mask = select_features.get_support()\n",
        "X_train_interactions_feature_selection = X_train_interactions.iloc[:, feature_mask]\n",
        "X_val_interactions_feature_selection = X_val_interactions.iloc[:, feature_mask]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLwd8ZlTliu_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "074d6dea-9ff1-454a-a84b-3cb21cf07bf9"
      },
      "source": [
        "linreg2=LinearRegression()\n",
        "train_score, test_score = fit_score_single_model(linreg2,model_names[0],X_train_interactions_feature_selection, X_val_interactions_feature_selection, y_train,y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinReg achieved a train score of 0.345 and test score of 0.364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epF3BEmItrMi"
      },
      "source": [
        "from X_train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQYwts6ztp_m"
      },
      "source": [
        "select_features = SelectKBest(mutual_info_regression, k=10)\n",
        "select_features = select_features.fit(X_train, y_train)\n",
        "\n",
        "# Get mask of columns that have good features\n",
        "feature_mask = select_features.get_support()\n",
        "X_train_feature_selection = X_train.iloc[:, feature_mask]\n",
        "X_val_feature_selection = X_val.iloc[:, feature_mask]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAPNi7Z9tQk9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b531bb60-cf08-4d0b-d39b-cc675bba9d34"
      },
      "source": [
        "linreg2=LinearRegression()\n",
        "train_score, test_score = fit_score_single_model(linreg2,model_names[0],X_train_feature_selection, X_val_feature_selection, y_train,y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinReg achieved a train score of 0.344 and test score of 0.368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hxf7jSQFuMOI"
      },
      "source": [
        "## Model Performance on Mutual Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "aqgqfM_luMOI",
        "outputId": "5a3a0b1a-6587-4fff-fc9d-b1942727bc2a"
      },
      "source": [
        "#choose to run the X_train blocks OR X_train_interactions blocks before running this\n",
        "\n",
        "#these results were using X_train selected features from the two blocks above\n",
        "all_models = fit_and_score_model(all_models, 'Mutual_Regression', X_train_feature_selection, X_val_feature_selection, y_train, y_val)\n",
        "\n",
        "\n",
        "print('_________________________\\n')\n",
        "compare_models('Mutual_Regression')\n",
        "all_models.loc[:, 'Mutual_Regression', :].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinReg achieved a train score of 0.344 and test score of 0.368\n",
            "LassoCV achieved a train score of 0.339 and test score of 0.351\n",
            "RidgeCV achieved a train score of 0.344 and test score of 0.367\n",
            "RF achieved a train score of 0.878 and test score of 0.248\n",
            "CART achieved a train score of 0.977 and test score of -0.610\n",
            "_________________________\n",
            "\n",
            "On average, scores improved by -0.07, and the most improvement was 0.00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TrainScore</th>\n",
              "      <th>TestScore</th>\n",
              "      <th>Model</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model names</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LinReg</th>\n",
              "      <td>0.344286</td>\n",
              "      <td>0.367867</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LassoCV</th>\n",
              "      <td>0.338597</td>\n",
              "      <td>0.350709</td>\n",
              "      <td>LassoCV(alphas=None, copy_X=True, cv=None, eps...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RidgeCV</th>\n",
              "      <td>0.344255</td>\n",
              "      <td>0.367407</td>\n",
              "      <td>RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>0.877738</td>\n",
              "      <td>0.248212</td>\n",
              "      <td>(DecisionTreeRegressor(ccp_alpha=0.0, criterio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CART</th>\n",
              "      <td>0.976900</td>\n",
              "      <td>-0.609515</td>\n",
              "      <td>DecisionTreeRegressor(ccp_alpha=0.0, criterion...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             TrainScore  ...                                              Model\n",
              "model names              ...                                                   \n",
              "LinReg         0.344286  ...  LinearRegression(copy_X=True, fit_intercept=Tr...\n",
              "LassoCV        0.338597  ...  LassoCV(alphas=None, copy_X=True, cv=None, eps...\n",
              "RidgeCV        0.344255  ...  RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=N...\n",
              "RF             0.877738  ...  (DecisionTreeRegressor(ccp_alpha=0.0, criterio...\n",
              "CART           0.976900  ...  DecisionTreeRegressor(ccp_alpha=0.0, criterion...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P-_9AherWeh"
      },
      "source": [
        "X_train_scaled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlmgZ0diq4_-"
      },
      "source": [
        "select_features = SelectKBest(mutual_info_regression, k=10)\n",
        "select_features = select_features.fit(X_train_scaled, y_train_scaled)\n",
        "\n",
        "# Get mask of columns that have good features\n",
        "feature_mask = select_features.get_support()\n",
        "X_train_feature_selection = X_train_scaled.iloc[:, feature_mask]\n",
        "X_val_feature_selection = X_val_scaled.iloc[:, feature_mask]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jQbuFWWupL0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec34ba2f-ecba-48fa-d88e-b7743c73cfe2"
      },
      "source": [
        "linreg3=LinearRegression()\n",
        "train_score, test_score = fit_score_single_model(linreg3, model_names[0],X_train_feature_selection, X_val_feature_selection, y_train_scaled,y_val_scaled)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinReg achieved a train score of 0.346 and test score of 0.379\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvcA6Mahu4GB"
      },
      "source": [
        "X_train_interactions_scaled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtVgQBMKu4GB"
      },
      "source": [
        "select_features = SelectKBest(mutual_info_regression, k=10)\n",
        "select_features = select_features.fit(X_train_interactions_scaled, y_train_scaled)\n",
        "\n",
        "# Get mask of columns that have good features\n",
        "feature_mask = select_features.get_support()\n",
        "X_train_interactions_feature_selection = X_train_interactions_scaled.iloc[:, feature_mask]\n",
        "X_val_interactions_feature_selection = X_val_interactions_scaled.iloc[:, feature_mask]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6-XlFeKu4GB",
        "outputId": "6521b60e-5061-4811-abd7-accfedf66446"
      },
      "source": [
        "linreg2=LinearRegression()\n",
        "train_score, test_score = fit_score_single_model(linreg2,model_names[0],X_train_interactions_feature_selection, X_val_interactions_feature_selection, y_train_scaled,y_val_scaled)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinReg achieved a train score of 0.343 and test score of 0.358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yzCwajoql70"
      },
      "source": [
        "## Model Performance on Mutual Regression (scaled)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "G0d_wbXtqkE5",
        "outputId": "002d69dd-8a18-4d4b-fad7-e9ff60c2c7b2"
      },
      "source": [
        "#choose to run X_train_scaled blocks OR X_train_interactions_scaled blocks before running this\n",
        "\n",
        "#the current results displayed are from X_train_scaled selected features\n",
        "all_models = fit_and_score_model(all_models, 'Mutual_Regression (scaled)', X_train_feature_selection, X_val_feature_selection, y_train_scaled, y_val_scaled)\n",
        "\n",
        "\n",
        "print('_________________________\\n')\n",
        "compare_models('Mutual_Regression (scaled)')\n",
        "all_models.loc[:, 'Mutual_Regression (scaled)', :].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinReg achieved a train score of 0.346 and test score of 0.379\n",
            "LassoCV achieved a train score of 0.341 and test score of 0.358\n",
            "RidgeCV achieved a train score of 0.346 and test score of 0.377\n",
            "RF achieved a train score of 0.877 and test score of 0.258\n",
            "CART achieved a train score of 0.976 and test score of -0.426\n",
            "_________________________\n",
            "\n",
            "On average, scores improved by -0.03, and the most improvement was 0.01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TrainScore</th>\n",
              "      <th>TestScore</th>\n",
              "      <th>Model</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model names</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LinReg</th>\n",
              "      <td>0.346013</td>\n",
              "      <td>0.378511</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LassoCV</th>\n",
              "      <td>0.341012</td>\n",
              "      <td>0.357717</td>\n",
              "      <td>LassoCV(alphas=None, copy_X=True, cv=None, eps...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RidgeCV</th>\n",
              "      <td>0.345944</td>\n",
              "      <td>0.377349</td>\n",
              "      <td>RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>0.877126</td>\n",
              "      <td>0.257728</td>\n",
              "      <td>(DecisionTreeRegressor(ccp_alpha=0.0, criterio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CART</th>\n",
              "      <td>0.975718</td>\n",
              "      <td>-0.425983</td>\n",
              "      <td>DecisionTreeRegressor(ccp_alpha=0.0, criterion...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             TrainScore  ...                                              Model\n",
              "model names              ...                                                   \n",
              "LinReg         0.346013  ...  LinearRegression(copy_X=True, fit_intercept=Tr...\n",
              "LassoCV        0.341012  ...  LassoCV(alphas=None, copy_X=True, cv=None, eps...\n",
              "RidgeCV        0.345944  ...  RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=N...\n",
              "RF             0.877126  ...  (DecisionTreeRegressor(ccp_alpha=0.0, criterio...\n",
              "CART           0.975718  ...  DecisionTreeRegressor(ccp_alpha=0.0, criterion...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy7TYA0nggc9"
      },
      "source": [
        "## ? Selecting columns based on **p-value**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu0W7JmysgLb"
      },
      "source": [
        "\n",
        "https://towardsdatascience.com/feature-selection-correlation-and-p-value-da8921bfb3cf\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNLi7wyqhz0h"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELwsj_ydhLch",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "4ca01079-3c75-4e4a-fd90-7353f20012dc"
      },
      "source": [
        "corr = X_train_interactions.corr()\n",
        "sns.heatmap(corr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3d6040f898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SphrVZhKMpui"
      },
      "source": [
        "Assuming dataset is linear, use **Pearson**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMcOMSkFk71G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "3b53cd23-abb9-4a0f-a6f8-1ef7996d2940"
      },
      "source": [
        "corr2=X_train_interactions.corr(method=\"pearson\")\n",
        "corr2= corr2[corr2>=abs(0.8)]\n",
        "sns.heatmap(corr2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3d5fb11c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLfYFVJT_c3t"
      },
      "source": [
        "# Grid Search\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAKLTDKH-kYU"
      },
      "source": [
        "For CART"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8RQBsWe_c3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ff3b2c5-25a1-423c-a499-f3b2d58e45eb"
      },
      "source": [
        "import numpy as np\n",
        "# Dictionary of parameters to search\n",
        "params_to_search = {\n",
        "    'criterion': ['mse', 'friedman_mse'],\n",
        "    'min_samples_leaf': [1, 2, 5, 10, 20,25,30],\n",
        "    'max_features': ['auto', 'log2', None,'sqrt']\n",
        "}\n",
        "\n",
        "# Initialize a model\n",
        "mdl = DecisionTreeRegressor(random_state=0)\n",
        "# Initialize the grid search\n",
        "optimized_dt = GridSearchCV(mdl, params_to_search, scoring=['r2'], refit=False, cv=5)\n",
        "# Run the grid search\n",
        "optimized_dt.fit(X_train, y_train)\n",
        "\n",
        "# Find the model with the highest test score\n",
        "\n",
        "cv_result_df = pd.DataFrame(optimized_dt.cv_results_)\n",
        "best_model_params_index = cv_result_df.mean_test_r2.idxmax()\n",
        "best_model_params = cv_result_df.params[best_model_params_index]\n",
        "\n",
        "print(f'The best model parameters are {best_model_params}') \n",
        "\n",
        "# Initialize the model \n",
        "best_model = DecisionTreeRegressor(random_state=0, **best_model_params)\n",
        "\n",
        "# Fit the model on the ENTIRE training set \n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model precision, recall, and score\n",
        "model_train_score = best_model.score(X_train,y_train)  # evaluate precision on test set\n",
        "model_test_score = best_model.score(X_val, y_val)  # evaluate recall on test set\n",
        "\n",
        "# Add model scores to all_models data frame\n",
        "all_models.loc['CART', 'Grid_Search'] = (model_train_score, model_test_score, best_model)\n",
        "all_models['TestScore'].loc['CART', ['Baseline', 'Grid_Search']]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best model parameters are {'criterion': 'mse', 'max_features': 'auto', 'min_samples_leaf': 30}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model names  technique  \n",
              "CART         Baseline      -0.346405\n",
              "             Grid_Search    0.309302\n",
              "Name: TestScore, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2LpbmfXHXLA",
        "outputId": "650a3bca-7585-404e-b37b-e4371f6fcf93"
      },
      "source": [
        "import numpy as np\n",
        "# Dictionary of parameters to search\n",
        "params_to_search = {\n",
        "    'splitter': ['best', 'random'],\n",
        "    'max_leaf_nodes':[None, 2,5,10,15,20,25],\n",
        "    'max_depth': np.arange(1,10)\n",
        "}\n",
        "\n",
        "# Initialize a model\n",
        "mdl = DecisionTreeRegressor(random_state=0)\n",
        "# Initialize the grid search\n",
        "optimized_dt = GridSearchCV(mdl, params_to_search, scoring=['r2'], refit=False, cv=5)\n",
        "# Run the grid search\n",
        "optimized_dt.fit(X_train, y_train)\n",
        "\n",
        "# Find the model with the highest test score\n",
        "\n",
        "cv_result_df = pd.DataFrame(optimized_dt.cv_results_)\n",
        "best_model_params_index = cv_result_df.mean_test_r2.idxmax()\n",
        "best_model_params = cv_result_df.params[best_model_params_index]\n",
        "\n",
        "print(f'The best model parameters are {best_model_params}') \n",
        "\n",
        "# Initialize the model \n",
        "best_model = DecisionTreeRegressor(random_state=0, **best_model_params)\n",
        "\n",
        "# Fit the model on the ENTIRE training set \n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model precision, recall, and score\n",
        "model_train_score = best_model.score(X_train,y_train)  # evaluate precision on test set\n",
        "model_test_score = best_model.score(X_val, y_val)  # evaluate recall on test set\n",
        "\n",
        "# Add model scores to all_models data frame\n",
        "all_models.loc['CART', 'Grid_Search'] = (model_train_score, model_test_score, best_model)\n",
        "all_models['TestScore'].loc['CART', ['Baseline', 'Grid_Search']]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best model parameters are {'max_depth': 4, 'max_leaf_nodes': 10, 'splitter': 'random'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model names  technique  \n",
              "CART         Baseline      -0.346405\n",
              "             Grid_Search    0.351463\n",
              "Name: TestScore, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnzD_uTZ7KEc"
      },
      "source": [
        "#all_models.loc[:,'Grid_Search',:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDWaz-4_-oKc"
      },
      "source": [
        "For RF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIf0Czgf-FYi",
        "outputId": "dc90ace8-dad1-4898-da76-8533e8d8b6f2"
      },
      "source": [
        "# Dictionary of parameters to search\n",
        "params_to_search = {\n",
        "    'criterion': ['mse', 'friedman_mse'],\n",
        "    'min_samples_leaf': [1, 2, 5, 10, 20,25,30],\n",
        "    \n",
        "}\n",
        "\n",
        "# Initialize a model\n",
        "mdl = RandomForestRegressor(random_state=0)\n",
        "# Initialize the grid search\n",
        "optimized_dt = GridSearchCV(mdl, params_to_search, scoring=['r2'], refit=False, cv=5)\n",
        "# Run the grid search\n",
        "optimized_dt.fit(X_train, y_train)\n",
        "\n",
        "# Find the model with the highest test score\n",
        "\n",
        "cv_result_df = pd.DataFrame(optimized_dt.cv_results_)\n",
        "best_model_params_index = cv_result_df.mean_test_r2.idxmax()\n",
        "best_model_params = cv_result_df.params[best_model_params_index]\n",
        "\n",
        "print(f'The best model parameters are {best_model_params}') \n",
        "\n",
        "# Initialize the model \n",
        "best_model = RandomForestRegressor(random_state=0, **best_model_params)\n",
        "\n",
        "# Fit the model on the ENTIRE training set \n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model precision, recall, and score\n",
        "model_train_score = best_model.score(X_train,y_train)  # evaluate precision on test set\n",
        "model_test_score = best_model.score(X_val, y_val)  # evaluate recall on test set\n",
        "\n",
        "# Add model scores to all_models data frame\n",
        "all_models.loc['RF', 'Grid_Search'] = (model_train_score, model_test_score, best_model)\n",
        "all_models['TestScore'].loc['RF', ['Baseline', 'Grid_Search']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best model parameters are {'criterion': 'mse', 'min_samples_leaf': 30}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model names  technique  \n",
              "RF           Baseline       0.339792\n",
              "             Grid_Search    0.377860\n",
              "Name: TestScore, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rpXb28kH9JN",
        "outputId": "42061c0b-c008-428e-8aa8-c3d40c69c632"
      },
      "source": [
        "# Dictionary of parameters to search\n",
        "params_to_search = {\n",
        "    'max_features': ['auto', 'log2', None,'sqrt'],\n",
        "    \"max_depth\":np.arange(1,10)\n",
        "}\n",
        "\n",
        "# Initialize a model\n",
        "mdl = RandomForestRegressor(random_state=0)\n",
        "# Initialize the grid search\n",
        "optimized_dt = GridSearchCV(mdl, params_to_search, scoring=['r2'], refit=False, cv=5)\n",
        "# Run the grid search\n",
        "optimized_dt.fit(X_train, y_train)\n",
        "\n",
        "# Find the model with the highest test score\n",
        "\n",
        "cv_result_df = pd.DataFrame(optimized_dt.cv_results_)\n",
        "best_model_params_index = cv_result_df.mean_test_r2.idxmax()\n",
        "best_model_params = cv_result_df.params[best_model_params_index]\n",
        "\n",
        "print(f'The best model parameters are {best_model_params}') \n",
        "\n",
        "# Initialize the model \n",
        "best_model = RandomForestRegressor(random_state=0, **best_model_params)\n",
        "\n",
        "# Fit the model on the ENTIRE training set \n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model precision, recall, and score\n",
        "model_train_score = best_model.score(X_train,y_train)  # evaluate precision on test set\n",
        "model_test_score = best_model.score(X_val, y_val)  # evaluate recall on test set\n",
        "\n",
        "# Add model scores to all_models data frame\n",
        "all_models.loc['RF', 'Grid_Search'] = (model_train_score, model_test_score, best_model)\n",
        "all_models['TestScore'].loc['RF', ['Baseline', 'Grid_Search']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best model parameters are {'max_depth': 3, 'max_features': 'auto'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model names  technique  \n",
              "RF           Baseline       0.339792\n",
              "             Grid_Search    0.378242\n",
              "Name: TestScore, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pDxXm5kLPFS",
        "outputId": "85302f6c-92b1-4f47-83db-53b2d0dc91ca"
      },
      "source": [
        "# Dictionary of parameters to search\n",
        "params_to_search = {\n",
        "    'n_estimators':np.arange(1,30)\n",
        "}\n",
        "\n",
        "# Initialize a model\n",
        "mdl = RandomForestRegressor(random_state=0)\n",
        "# Initialize the grid search\n",
        "optimized_dt = GridSearchCV(mdl, params_to_search, scoring=['r2'], refit=False, cv=5)\n",
        "# Run the grid search\n",
        "optimized_dt.fit(X_train, y_train)\n",
        "\n",
        "# Find the model with the highest test score\n",
        "\n",
        "cv_result_df = pd.DataFrame(optimized_dt.cv_results_)\n",
        "best_model_params_index = cv_result_df.mean_test_r2.idxmax()\n",
        "best_model_params = cv_result_df.params[best_model_params_index]\n",
        "\n",
        "print(f'The best model parameters are {best_model_params}') \n",
        "\n",
        "# Initialize the model \n",
        "best_model = RandomForestRegressor(random_state=0, **best_model_params)\n",
        "\n",
        "# Fit the model on the ENTIRE training set \n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model precision, recall, and score\n",
        "model_train_score = best_model.score(X_train,y_train)  # evaluate precision on test set\n",
        "model_test_score = best_model.score(X_val, y_val)  # evaluate recall on test set\n",
        "\n",
        "# Add model scores to all_models data frame\n",
        "all_models.loc['RF', 'Grid_Search'] = (model_train_score, model_test_score, best_model)\n",
        "all_models['TestScore'].loc['RF', ['Baseline', 'Grid_Search']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best model parameters are {'n_estimators': 29}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model names  technique  \n",
              "RF           Baseline       0.339792\n",
              "             Grid_Search    0.319159\n",
              "Name: TestScore, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flen3r8vAjsa"
      },
      "source": [
        "#all_models.loc[:,'Grid_Search',:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiBYBvL7AtlZ"
      },
      "source": [
        "Fpr RidgeCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDb6n96MApth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8005f7b3-00ac-4029-93f4-ee5c5b99b379"
      },
      "source": [
        "# Dictionary of parameters to search\n",
        "params_to_search = {\n",
        "    'fit_intercept': [True, False],\n",
        "    'normalize': [True,False],\n",
        "    'gcv_mode': ['auto', 'svd', 'eigen'],\n",
        "}\n",
        "\n",
        "# Initialize a model\n",
        "mdl = RidgeCV()\n",
        "# Initialize the grid search\n",
        "optimized_dt = GridSearchCV(mdl, params_to_search, scoring=['r2'], refit=False, cv=5)\n",
        "# Run the grid search\n",
        "optimized_dt.fit(X_train, y_train)\n",
        "\n",
        "# Find the model with the highest test score\n",
        "\n",
        "cv_result_df = pd.DataFrame(optimized_dt.cv_results_)\n",
        "best_model_params_index = cv_result_df.mean_test_r2.idxmax()\n",
        "best_model_params = cv_result_df.params[best_model_params_index]\n",
        "\n",
        "print(f'The best model parameters are {best_model_params}') \n",
        "\n",
        "# Initialize the model \n",
        "best_model = RidgeCV(**best_model_params)\n",
        "\n",
        "# Fit the model on the ENTIRE training set \n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model precision, recall, and score\n",
        "model_train_score = best_model.score(X_train,y_train)  # evaluate precision on test set\n",
        "model_test_score = best_model.score(X_val, y_val)  # evaluate recall on test set\n",
        "\n",
        "# Add model scores to all_models data frame\n",
        "all_models.loc['RidgeCV', 'Grid_Search'] = (model_train_score, model_test_score, best_model)\n",
        "all_models['TestScore'].loc['RidgeCV', ['Baseline', 'Grid_Search']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best model parameters are {'fit_intercept': True, 'gcv_mode': 'eigen', 'normalize': False}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model names  technique  \n",
              "RidgeCV      Baseline       0.374853\n",
              "             Grid_Search    0.374853\n",
              "Name: TestScore, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofunRp83D6ui"
      },
      "source": [
        "for LassoCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKV9sf9tEP0N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a9d4e52-8646-48ae-cfcd-0b0eb192cead"
      },
      "source": [
        "# Dictionary of parameters to search\n",
        "params_to_search = {\n",
        "    'fit_intercept': [True, False],\n",
        "    'normalize': [True,False],\n",
        "    'precompute':['auto',False,True],\n",
        "}\n",
        "\n",
        "# Initialize a model\n",
        "mdl = LassoCV()\n",
        "# Initialize the grid search\n",
        "optimized_dt = GridSearchCV(mdl, params_to_search, scoring=['r2'], refit=False, cv=5)\n",
        "# Run the grid search\n",
        "optimized_dt.fit(X_train, y_train)\n",
        "\n",
        "# Find the model with the highest test score\n",
        "\n",
        "cv_result_df = pd.DataFrame(optimized_dt.cv_results_)\n",
        "best_model_params_index = cv_result_df.mean_test_r2.idxmax()\n",
        "best_model_params = cv_result_df.params[best_model_params_index]\n",
        "\n",
        "print(f'The best model parameters are {best_model_params}') \n",
        "\n",
        "# Initialize the model \n",
        "best_model = LassoCV(**best_model_params)\n",
        "\n",
        "# Fit the model on the ENTIRE training set \n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model precision, recall, and score\n",
        "model_train_score = best_model.score(X_train,y_train)  # evaluate precision on test set\n",
        "model_test_score = best_model.score(X_val, y_val)  # evaluate recall on test set\n",
        "\n",
        "# Add model scores to all_models data frame\n",
        "all_models.loc['LassoCV', 'Grid_Search'] = (model_train_score, model_test_score, best_model)\n",
        "all_models['TestScore'].loc['LassoCV', ['Baseline', 'Grid_Search']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best model parameters are {'fit_intercept': True, 'normalize': True, 'precompute': True}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model names  technique  \n",
              "LassoCV      Baseline       0.348774\n",
              "             Grid_Search    0.357671\n",
              "Name: TestScore, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZkjCz-JKhzS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e511b02-0cb7-4cc7-d593-162284210804"
      },
      "source": [
        "# Dictionary of parameters to search\n",
        "params_to_search = {\n",
        "    'cv':[5,10,15,20]\n",
        "}\n",
        "\n",
        "# Initialize a model\n",
        "mdl = LassoCV()\n",
        "# Initialize the grid search\n",
        "optimized_dt = GridSearchCV(mdl, params_to_search, scoring=['r2'], refit=False, cv=5)\n",
        "# Run the grid search\n",
        "optimized_dt.fit(X_train, y_train)\n",
        "\n",
        "# Find the model with the highest test score\n",
        "\n",
        "cv_result_df = pd.DataFrame(optimized_dt.cv_results_)\n",
        "best_model_params_index = cv_result_df.mean_test_r2.idxmax()\n",
        "best_model_params = cv_result_df.params[best_model_params_index]\n",
        "\n",
        "print(f'The best model parameters are {best_model_params}') \n",
        "\n",
        "# Initialize the model \n",
        "best_model = LassoCV(**best_model_params)\n",
        "\n",
        "# Fit the model on the ENTIRE training set \n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model precision, recall, and score\n",
        "model_train_score = best_model.score(X_train,y_train)  # evaluate precision on test set\n",
        "model_test_score = best_model.score(X_val, y_val)  # evaluate recall on test set\n",
        "\n",
        "# Add model scores to all_models data frame\n",
        "all_models.loc['LassoCV', 'Grid_Search'] = (model_train_score, model_test_score, best_model)\n",
        "all_models['TestScore'].loc['LassoCV', ['Baseline', 'Grid_Search']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best model parameters are {'cv': 20}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model names  technique  \n",
              "LassoCV      Baseline       0.348774\n",
              "             Grid_Search    0.352312\n",
              "Name: TestScore, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uV8mmbnGF18v"
      },
      "source": [
        "For LinReg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzsmT8BCF0py",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e7e5344-480d-4a9c-c747-3ba442f0484a"
      },
      "source": [
        "# Dictionary of parameters to search\n",
        "params_to_search = {\n",
        "    'fit_intercept': [True, False],\n",
        "    'normalize': [True,False],\n",
        "    'n_jobs':[0,1,2,3]\n",
        "}\n",
        "\n",
        "# Initialize a model\n",
        "mdl = LinearRegression()\n",
        "# Initialize the grid search\n",
        "optimized_dt = GridSearchCV(mdl, params_to_search, scoring=['r2'], refit=False, cv=5)\n",
        "# Run the grid search\n",
        "optimized_dt.fit(X_train, y_train)\n",
        "\n",
        "# Find the model with the highest test score\n",
        "\n",
        "cv_result_df = pd.DataFrame(optimized_dt.cv_results_)\n",
        "best_model_params_index = cv_result_df.mean_test_r2.idxmax()\n",
        "best_model_params = cv_result_df.params[best_model_params_index]\n",
        "\n",
        "print(f'The best model parameters are {best_model_params}') \n",
        "\n",
        "# Initialize the model \n",
        "best_model = LinearRegression(**best_model_params)\n",
        "\n",
        "# Fit the model on the ENTIRE training set \n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model precision, recall, and score\n",
        "model_train_score = best_model.score(X_train,y_train)  # evaluate precision on test set\n",
        "model_test_score = best_model.score(X_val, y_val)  # evaluate recall on test set\n",
        "\n",
        "# Add model scores to all_models data frame\n",
        "all_models.loc['LinReg', 'Grid_Search'] = (model_train_score, model_test_score, best_model)\n",
        "all_models['TestScore'].loc['LinReg', ['Baseline', 'Grid_Search']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best model parameters are {'fit_intercept': False, 'n_jobs': 0, 'normalize': True}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model names  technique  \n",
              "LinReg       Baseline       0.371280\n",
              "             Grid_Search    0.369227\n",
              "Name: TestScore, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfmBpnduHczG"
      },
      "source": [
        "Grid Search Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kes3YyILHbEJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "caf4245d-62a0-4b6e-950d-63d3ca762830"
      },
      "source": [
        "all_models.loc[:,'Grid_Search',:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TrainScore</th>\n",
              "      <th>TestScore</th>\n",
              "      <th>Model</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model names</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LinReg</th>\n",
              "      <td>0.367663</td>\n",
              "      <td>0.369227</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Fa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LassoCV</th>\n",
              "      <td>0.341227</td>\n",
              "      <td>0.352312</td>\n",
              "      <td>LassoCV(alphas=None, copy_X=True, cv=20, eps=0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RidgeCV</th>\n",
              "      <td>0.366021</td>\n",
              "      <td>0.374853</td>\n",
              "      <td>RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RF</th>\n",
              "      <td>0.898089</td>\n",
              "      <td>0.319159</td>\n",
              "      <td>(DecisionTreeRegressor(ccp_alpha=0.0, criterio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CART</th>\n",
              "      <td>0.345567</td>\n",
              "      <td>0.351463</td>\n",
              "      <td>DecisionTreeRegressor(ccp_alpha=0.0, criterion...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             TrainScore  ...                                              Model\n",
              "model names              ...                                                   \n",
              "LinReg         0.367663  ...  LinearRegression(copy_X=True, fit_intercept=Fa...\n",
              "LassoCV        0.341227  ...  LassoCV(alphas=None, copy_X=True, cv=20, eps=0...\n",
              "RidgeCV        0.366021  ...  RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=N...\n",
              "RF             0.898089  ...  (DecisionTreeRegressor(ccp_alpha=0.0, criterio...\n",
              "CART           0.345567  ...  DecisionTreeRegressor(ccp_alpha=0.0, criterion...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRfat8qalsrq"
      },
      "source": [
        "# Stacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Jj-ZE1u_3Nl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0457e0c8-c512-4bda-e033-654435e55329"
      },
      "source": [
        "'''A stacked model that begins with clustering'''\n",
        "technique_name = 'Stacking'\n",
        "\n",
        "# Initialize the clustering model\n",
        "model = KMeans(n_init=10, n_clusters=8, random_state=0)\n",
        "model.fit(X_train)\n",
        "\n",
        "# Stack training data\n",
        "X_train_prediction = pd.Series(model.predict(X_train), \n",
        "                            name='cluster',\n",
        "                            index=X_train.index)\n",
        "\n",
        "# One-hot-encode cluster numbers\n",
        "X_train_prediction = pd.get_dummies(X_train_prediction)\n",
        "# Add cluster numbers to features\n",
        "X_train_stacked = X_train.join(X_train_prediction)\n",
        "\n",
        "# Stack testing data\n",
        "X_val_prediction = pd.Series(model.predict(X_val),\n",
        "                             name='cluster',\n",
        "                             index=X_val.index)\n",
        "# One-hot-encode cluster numbers\n",
        "X_val_prediction = pd.get_dummies(X_val_prediction)\n",
        "# Get cluster numbers that weren't predicted in the testing set\n",
        "missing_cluster_columns = X_train_prediction.columns.difference(X_val_prediction.columns)\n",
        "# Add missing cluster dummy variables\n",
        "X_val_prediction[missing_cluster_columns] = 0 \n",
        "# Add cluster numbers to features\n",
        "X_val_stacked = X_val.join(X_val_prediction)\n",
        "\n",
        "# We will use logistic regression instead of a decision tree at the higher-level classifier\n",
        "all_models = fit_and_score_model(all_models, technique_name, X_train_stacked, X_val_stacked, y_train, y_val)\n",
        "compare_models(technique_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinReg achieved a train score of 0.372 and test score of 0.366\n",
            "LassoCV achieved a train score of 0.339 and test score of 0.349\n",
            "RidgeCV achieved a train score of 0.367 and test score of 0.375\n",
            "RF achieved a train score of 0.903 and test score of 0.323\n",
            "CART achieved a train score of 1.000 and test score of -0.261\n",
            "On average, scores improved by 0.01, and the most improvement was 0.09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EylVidzUwtTc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a47487e-d2d5-4098-b3e9-ce94afe0cf7c"
      },
      "source": [
        "'''A stacked model that begins with clustering'''\n",
        "technique_name = 'Stacking'\n",
        "\n",
        "# Initialize the clustering model\n",
        "model = KMeans(n_init=10, n_clusters=8, random_state=0)\n",
        "model.fit(X_train)\n",
        "\n",
        "# Stack training data\n",
        "X_train_prediction = pd.Series(model.predict(X_train), \n",
        "                            name='cluster',\n",
        "                            index=X_train.index)\n",
        "\n",
        "# One-hot-encode cluster numbers\n",
        "X_train_prediction = pd.get_dummies(X_train_prediction)\n",
        "# Add cluster numbers to features\n",
        "X_train_stacked = X_train.join(X_train_prediction)\n",
        "\n",
        "# Stack testing data\n",
        "X_val_prediction = pd.Series(model.predict(X_val),\n",
        "                             name='cluster',\n",
        "                             index=X_val.index)\n",
        "# One-hot-encode cluster numbers\n",
        "X_val_prediction = pd.get_dummies(X_val_prediction)\n",
        "# Get cluster numbers that weren't predicted in the testing set\n",
        "missing_cluster_columns = X_train_prediction.columns.difference(X_val_prediction.columns)\n",
        "# Add missing cluster dummy variables\n",
        "X_val_prediction[missing_cluster_columns] = 0 \n",
        "# Add cluster numbers to features\n",
        "X_val_stacked = X_val.join(X_val_prediction)\n",
        "\n",
        "# We will use logistic regression instead of a decision tree at the higher-level classifier\n",
        "all_models = fit_and_score_model(all_models, technique_name, X_train_stacked, X_val_stacked, y_train, y_val)\n",
        "compare_models(technique_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinReg achieved a train score of 0.372 and test score of 0.366\n",
            "LassoCV achieved a train score of 0.339 and test score of 0.349\n",
            "RidgeCV achieved a train score of 0.367 and test score of 0.375\n",
            "RF achieved a train score of 0.903 and test score of 0.349\n",
            "CART achieved a train score of 1.000 and test score of -0.303\n",
            "On average, scores improved by 0.01, and the most improvement was 0.04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE2WRy-ljlmS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "aa66b68a-18ec-4ae5-8ba9-24cc773820ed"
      },
      "source": [
        "X_train_interactions_overall"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TOMATOMETER score</th>\n",
              "      <th>TOMATOMETER Count</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Genre_Action</th>\n",
              "      <th>Genre_Art&amp;Foreign</th>\n",
              "      <th>Genre_Classics</th>\n",
              "      <th>Genre_Comedy</th>\n",
              "      <th>Genre_Documentary</th>\n",
              "      <th>Genre_Drama</th>\n",
              "      <th>Genre_Horror</th>\n",
              "      <th>Genre_Kids&amp;Family</th>\n",
              "      <th>Genre_Mystery</th>\n",
              "      <th>Genre_Romance</th>\n",
              "      <th>Genre_SciFi</th>\n",
              "      <th>Rating_G</th>\n",
              "      <th>Rating_NC17</th>\n",
              "      <th>Rating_NR</th>\n",
              "      <th>Rating_PG</th>\n",
              "      <th>Rating_PG-13</th>\n",
              "      <th>Rating_R</th>\n",
              "      <th>cast1_oscar_nom</th>\n",
              "      <th>cast1_oscars</th>\n",
              "      <th>cast2_oscar_nom</th>\n",
              "      <th>cast2_oscars</th>\n",
              "      <th>cast3_oscar_nom</th>\n",
              "      <th>cast3_oscars</th>\n",
              "      <th>cast1_FB_likes</th>\n",
              "      <th>cast2_FB_likes</th>\n",
              "      <th>cast3_FB_likes</th>\n",
              "      <th>dir_oscar_nom</th>\n",
              "      <th>dir_oscars</th>\n",
              "      <th>director_awards</th>\n",
              "      <th>director_facebook_likes</th>\n",
              "      <th>Genre_Horror + Rating_G + Rating_NR</th>\n",
              "      <th>total_cast_facebook_likes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>95.0</td>\n",
              "      <td>19</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>488.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1222.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>73.0</td>\n",
              "      <td>15</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1101.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>92.0</td>\n",
              "      <td>7</td>\n",
              "      <td>104</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1101.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1210</th>\n",
              "      <td>40.0</td>\n",
              "      <td>190</td>\n",
              "      <td>120</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>0</td>\n",
              "      <td>13367.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>720</th>\n",
              "      <td>63.0</td>\n",
              "      <td>104</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>338.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>956.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1661.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>789</th>\n",
              "      <td>50.0</td>\n",
              "      <td>34</td>\n",
              "      <td>83</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>0</td>\n",
              "      <td>955.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>40.0</td>\n",
              "      <td>129</td>\n",
              "      <td>110</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>9000.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>0</td>\n",
              "      <td>10367.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>968</th>\n",
              "      <td>96.0</td>\n",
              "      <td>15</td>\n",
              "      <td>130</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1101.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>952</th>\n",
              "      <td>78.0</td>\n",
              "      <td>11</td>\n",
              "      <td>78</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1101.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1273</th>\n",
              "      <td>92.0</td>\n",
              "      <td>37</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1101.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>893 rows  35 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      TOMATOMETER score  ...  total_cast_facebook_likes\n",
              "70                 95.0  ...                     1222.0\n",
              "75                 73.0  ...                     1101.0\n",
              "889                92.0  ...                     1101.0\n",
              "1210               40.0  ...                    13367.0\n",
              "720                63.0  ...                     1661.0\n",
              "...                 ...  ...                        ...\n",
              "789                50.0  ...                      955.0\n",
              "256                40.0  ...                    10367.0\n",
              "968                96.0  ...                     1101.0\n",
              "952                78.0  ...                     1101.0\n",
              "1273               92.0  ...                     1101.0\n",
              "\n",
              "[893 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1XZ-EMqUuCy"
      },
      "source": [
        "With feature engineering (used for \"Stacking\" in all_models)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhjpNsviTnJl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9b3ba08-acb2-4e73-b205-2b602c35c230"
      },
      "source": [
        "'''A stacked model that begins with clustering'''\n",
        "technique_name = 'Stacking'\n",
        "\n",
        "# Initialize the clustering model\n",
        "model = KMeans(n_init=10, n_clusters=8, random_state=0)\n",
        "model.fit(X_train_interactions_overall)\n",
        "\n",
        "# Stack training data\n",
        "X_train_prediction = pd.Series(model.predict(X_train_interactions_overall), \n",
        "                            name='cluster',\n",
        "                            index=X_train_interactions_overall.index)\n",
        "\n",
        "# One-hot-encode cluster numbers\n",
        "X_train_prediction = pd.get_dummies(X_train_prediction)\n",
        "# Add cluster numbers to features\n",
        "X_train_stacked = X_train_interactions_overall.join(X_train_prediction)\n",
        "\n",
        "# Stack testing data\n",
        "X_val_prediction = pd.Series(model.predict(X_val_interactions_overall),\n",
        "                             name='cluster',\n",
        "                             index=X_val_interactions_overall.index)\n",
        "# One-hot-encode cluster numbers\n",
        "X_val_prediction = pd.get_dummies(X_val_prediction)\n",
        "# Get cluster numbers that weren't predicted in the testing set\n",
        "missing_cluster_columns = X_train_prediction.columns.difference(X_val_prediction.columns)\n",
        "# Add missing cluster dummy variables\n",
        "X_val_prediction[missing_cluster_columns] = 0 \n",
        "# Add cluster numbers to features\n",
        "X_val_stacked = X_val_interactions_overall.join(X_val_prediction)\n",
        "\n",
        "# We will use logistic regression instead of a decision tree at the higher-level classifier\n",
        "all_models = fit_and_score_model(all_models, technique_name, X_train_stacked, X_val_stacked, y_train, y_val)\n",
        "compare_models(technique_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinReg achieved a train score of 0.365 and test score of -184023294.141\n",
            "LassoCV achieved a train score of 0.339 and test score of 0.349\n",
            "RidgeCV achieved a train score of 0.368 and test score of 0.380\n",
            "RF achieved a train score of 0.901 and test score of 0.338\n",
            "CART achieved a train score of 1.000 and test score of -0.411\n",
            "On average, scores improved by -36804658.91, and the most improvement was 0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6zKtus40PWH"
      },
      "source": [
        "# Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuoYuV6P_3Ns",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8db3259-e08d-44c6-9122-2ea6aae8aa55"
      },
      "source": [
        "from sklearn.ensemble import VotingRegressor\n",
        "technique_name = 'Bagging'\n",
        "\n",
        "# Get a list of initialized models for bagging\n",
        "models_dict = make_models()\n",
        "# Convert models to list of tuples (required by documentation)\n",
        "model_list = list(models_dict.items()) \n",
        "\n",
        "# Set the weights for each model as their relative performance\n",
        "bagging_weights = all_models.TestScore[:,'Baseline'].values\n",
        "\n",
        "# Initialize bagging model\n",
        "bagging_model = VotingRegressor(model_list, weights=bagging_weights)\n",
        "# Fit the bagging model (i.e., each of the four models that are bagged)\n",
        "bagging_model.fit(X_train.values, y_train.values)\n",
        "\n",
        "# Predict the target using the bagged model\n",
        "bagging_prediction = bagging_model.predict(X_val)\n",
        "\n",
        "# Evaluate ensemble model\n",
        "fit_and_score_model(all_models,technique_name,X_train,X_val,y_train,y_val)\n",
        "\n",
        "# Add ensemble model to all_models dataframe (commenting this out bc fit_and)score_model does this already)\n",
        "#all_models.loc[:, technique_name, :] = (trainscore, testscore, None) \n",
        "compare_models(technique_name)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinReg achieved a train score of 0.368 and test score of 0.371\n",
            "LassoCV achieved a train score of 0.339 and test score of 0.349\n",
            "RidgeCV achieved a train score of 0.366 and test score of 0.375\n",
            "RF achieved a train score of 0.902 and test score of 0.354\n",
            "CART achieved a train score of 1.000 and test score of -0.271\n",
            "On average, scores improved by 0.02, and the most improvement was 0.08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H45WXz5hJhV1"
      },
      "source": [
        "##Using differnt classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ1sRaOxksgc"
      },
      "source": [
        "Find the one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHvIK9Bqku1f",
        "outputId": "d7e0611f-f4d7-47d8-d3a6-5d775c905147"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "technique_name = 'bagging_all'\n",
        "\n",
        "# Get a list of initialized models for bagging\n",
        "models_dict = make_models()\n",
        "models_dict.pop('CART')\n",
        "#models_dict.pop('RF')\n",
        "\n",
        "engineering_techniques_use = ('Baseline',  # Set of baseline models\n",
        "                          #'Scaling',  # Set of models trained with scaled data\n",
        "                          #'Feature_Engineering',  # Set of models trained with engineered features\n",
        "                          #'Feature_Engineering_overall', # trying\n",
        "                          'Feature_Selection',  # Set of models trained with \"selected\" features\n",
        "                          'Grid_Search',  # Set of models trained via grid search\n",
        "                          #'Stacking',  # Set of stacked model \n",
        "                          'Bagging',   # A bagged model\n",
        "                          #'Mutual_Regression (scaled)', # Set of models trained with features from MI using scaled data\n",
        "                          'Mutual_Regression' # Set of models trained with features from MI using normal data\n",
        "                          )\n",
        "\n",
        "# Convert models to list of tuples (required by documentation)\n",
        "model_list = list(models_dict.items()) \n",
        "bagging_prediction_ultimate = []\n",
        "bagging_weights =[]\n",
        "bagging_weight2 = []\n",
        "\n",
        "for  k in engineering_techniques_use:\n",
        "\n",
        "  # Set the weights for each model as their relative performance\n",
        "  bagging_collector = all_models.TestScore[:,k].values\n",
        "  bagging_weights.extend(bagging_collector[:4]) \n",
        "  bagging_weight2.append(bagging_collector[:4]) \n",
        "  #Initialize bagging model\n",
        "print(bagging_weights)\n",
        "print(bagging_weight2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.3712804963638475, 0.3487735520917514, 0.37485310335255473, 0.3397915289081095, 0.3670586844358734, 0.3487735520917514, 0.37327630699875003, 0.34201920725017454, 0.36922698886613137, 0.3523123986199891, 0.37485305819557435, 0.31915910730342967, 0.3712804963638475, 0.3487735520917514, 0.37485310335255473, 0.3539881834589317, 0.3678670882112004, 0.35070923803106757, 0.3674072834495563, 0.24821172384365478]\n",
            "[array([0.3712805 , 0.34877355, 0.3748531 , 0.33979153]), array([0.36705868, 0.34877355, 0.37327631, 0.34201921]), array([0.36922699, 0.3523124 , 0.37485306, 0.31915911]), array([0.3712805 , 0.34877355, 0.3748531 , 0.35398818]), array([0.36786709, 0.35070924, 0.36740728, 0.24821172])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7Rn-59smgaI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5492ab88-562b-4c79-b5e6-ef401d7bddc7"
      },
      "source": [
        "for  j in bagging_weight2:\n",
        "  for i in range(len(model_list)):\n",
        "    model_list[i][1].fit(X_train.values, y_train.values)\n",
        "    prediction = model_list[i][1].predict(X_val)\n",
        "\n",
        "    if bagging_prediction_ultimate==[]:\n",
        "      bagging_prediction_ultimate = prediction*j[i]/sum(bagging_weights)\n",
        "    else:\n",
        "      bagging_prediction_ultimate = bagging_prediction_ultimate+prediction*j[i]/sum(bagging_weights)\n",
        "      \n",
        "\n",
        "\n",
        "test_score = r2_score(y_val,bagging_prediction_ultimate)\n",
        "\n",
        "all_models.loc['LinReg', 'bagging_all'] = (0,test_score,None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-ddc80f462b73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbagging_prediction_ultimate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mall_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LinReg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bagging_all'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   1599\u001b[0m                             \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m                         )\n\u001b[0;32m-> 1601\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m                         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   1665\u001b[0m                     \u001b[0;31m# Exclude zero-len for e.g. boolean masking that is all-false\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m                     raise ValueError(\n\u001b[0;32m-> 1667\u001b[0;31m                         \u001b[0;34m\"cannot set using a multi-index \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1668\u001b[0m                         \u001b[0;34m\"selection indexer with a different \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m                         \u001b[0;34m\"length than the value\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot set using a multi-index selection indexer with a different length than the value"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZB_ewywxZxHe"
      },
      "source": [
        "Overall improvements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JruW6nCSJfak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dff9e270-c41d-48cb-fd81-3d6f19c2f7bf"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "technique_name = 'Bagging_feature_engi_average'\n",
        "\n",
        "# Get a list of initialized models for bagging\n",
        "models_dict = make_models()\n",
        "models_dict.pop('CART')\n",
        "#models_dict.pop('RF')\n",
        "\n",
        "# Convert models to list of tuples (required by documentation)\n",
        "model_list = list(models_dict.items()) \n",
        "\n",
        "# Set the weights for each model as their relative performance\n",
        "bagging_weights = all_models.TestScore[:,'Feature_Engineering_overall'].values\n",
        "bagging_weights = bagging_weights[:4]\n",
        "#Initialize bagging model\n",
        "\n",
        "bagging_prediction_f = []\n",
        "\n",
        "for i in range(len(model_list)):\n",
        "  model_list[i][1].fit(X_train_interactions_overall.values, y_train.values)\n",
        "  prediction = model_list[i][1].predict(X_val_interactions_overall)\n",
        "\n",
        "  if bagging_prediction_f==[]:\n",
        "    bagging_prediction_f = prediction*bagging_weights[i]/sum(bagging_weights)\n",
        "  else:\n",
        "    bagging_prediction_f = bagging_prediction_f+prediction*bagging_weights[i]/sum(bagging_weights)\n",
        "    \n",
        "\n",
        "\n",
        "r2_score(y_val,bagging_prediction_f)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38409822479510525"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-phe1a4ddLl"
      },
      "source": [
        "mutual"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9JxzKTVdcyQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9382ad59-1ac7-4d96-8fa6-7efa81915c9f"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "technique_name = 'Bagging_mutual'\n",
        "\n",
        "# Get a list of initialized models for bagging\n",
        "models_dict = make_models()\n",
        "models_dict.pop('CART')\n",
        "#models_dict.pop('RF')\n",
        "\n",
        "# Convert models to list of tuples (required by documentation)\n",
        "model_list = list(models_dict.items()) \n",
        "\n",
        "# Set the weights for each model as their relative performance\n",
        "bagging_weights = all_models.TestScore[:,'Mutual_Regression (scaled)'].values\n",
        "bagging_weights = bagging_weights[:4]\n",
        "#Initialize bagging model\n",
        "\n",
        "bagging_prediction_m = []\n",
        "\n",
        "for i in range(len(model_list)):\n",
        "  model_list[i][1].fit(X_train_scaled.values, y_train_scaled.values)\n",
        "  prediction = model_list[i][1].predict(X_val_scaled)\n",
        "\n",
        "  if bagging_prediction_m==[]:\n",
        "    bagging_prediction_m = prediction*bagging_weights[i]/sum(bagging_weights)\n",
        "  else:\n",
        "    bagging_prediction_m = bagging_prediction_m+prediction*bagging_weights[i]/sum(bagging_weights)\n",
        "    \n",
        "\n",
        "\n",
        "r2_score(y_val_scaled,bagging_prediction_m )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3806071608154279"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0PFSipKjPjr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c392aa63-13e0-43bf-f7de-6997d1fdbc7a"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "technique_name = 'Bagging_scaling'\n",
        "\n",
        "# Get a list of initialized models for bagging\n",
        "models_dict = make_models()\n",
        "models_dict.pop('CART')\n",
        "#models_dict.pop('RF')\n",
        "\n",
        "# Convert models to list of tuples (required by documentation)\n",
        "model_list = list(models_dict.items()) \n",
        "\n",
        "# Set the weights for each model as their relative performance\n",
        "bagging_weights = all_models.TestScore[:,'Scaling'].values\n",
        "bagging_weights = bagging_weights[:4]\n",
        "#Initialize bagging model\n",
        "\n",
        "bagging_prediction_s = []\n",
        "\n",
        "for i in range(len(model_list)):\n",
        "  model_list[i][1].fit(X_train_scaled.values, y_train_scaled.values)\n",
        "  prediction = model_list[i][1].predict(X_val_scaled)\n",
        "\n",
        "  if bagging_prediction_s==[]:\n",
        "    bagging_prediction_s = prediction*bagging_weights[i]/sum(bagging_weights)\n",
        "  else:\n",
        "    bagging_prediction_s = bagging_prediction_s+prediction*bagging_weights[i]/sum(bagging_weights)\n",
        "    \n",
        "\n",
        "\n",
        "r2_score(y_val_scaled,bagging_prediction_s )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3856208884044049"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiAVvwlsaSWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7498a5a5-1e34-439a-82f2-287aee95fa21"
      },
      "source": [
        "all_models['TestScore'].sort_values(ascending = False)[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model names  technique                  \n",
              "RidgeCV      Stacking                       0.379721\n",
              "LinReg       Mutual_Regression (scaled)     0.378511\n",
              "RidgeCV      Mutual_Regression (scaled)     0.377349\n",
              "             Feature_Engineering_overall    0.375641\n",
              "             Feature_Engineering            0.375641\n",
              "             Baseline                       0.374853\n",
              "             Bagging                        0.374853\n",
              "             Grid_Search                    0.374853\n",
              "             Feature_Selection              0.373276\n",
              "LinReg       Bagging                        0.371280\n",
              "             Baseline                       0.371280\n",
              "             Feature_Engineering_overall    0.371158\n",
              "             Feature_Engineering            0.371158\n",
              "             Grid_Search                    0.369227\n",
              "             Scaling                        0.368755\n",
              "RidgeCV      Scaling                        0.367947\n",
              "LinReg       Mutual_Regression              0.367867\n",
              "RidgeCV      Mutual_Regression              0.367407\n",
              "LinReg       Feature_Selection              0.367059\n",
              "LassoCV      Scaling                        0.365217\n",
              "Name: TestScore, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR94_44afpMm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91eb6a1e-451a-45b9-b250-c395d7fbb8f6"
      },
      "source": [
        "fo = all_models.loc[:,'Feature_Engineering_overall',:]['TestScore'].sort_values(ascending = False)[:4].mean()\n",
        "print(fo)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3590642953462805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwcxAS-rgRJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c35c2a81-ab5f-42cd-df52-9f787acded1a"
      },
      "source": [
        "m = all_models.loc[:,'Mutual_Regression (scaled)',:]['TestScore'].sort_values(ascending = False)[:4].mean()\n",
        "s = all_models.loc[:,'Scaling',:]['TestScore'].sort_values(ascending = False)[:4].mean()\n",
        "print(m)\n",
        "print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.34282624300374154\n",
            "0.36103143830186013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CeBvxTHhRZL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f370ee7-e0a6-4099-9b0a-4c6ad3839df0"
      },
      "source": [
        "bagging_prediction_avenger = bagging_prediction_m*m/(s+m)+bagging_prediction_s*s/(s+m)\n",
        "\n",
        "r2_score(y_val_scaled,bagging_prediction_avenger)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3833858782257835"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOpuxEHcek1M"
      },
      "source": [
        "mutual regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxdAz2YreoPa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "415e4568-85f9-4940-8f78-0335b971fc77"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "technique_name = 'Bagging_scaling'\n",
        "\n",
        "# Get a list of initialized models for bagging\n",
        "models_dict = make_models()\n",
        "models_dict.pop('CART')\n",
        "#models_dict.pop('RF')\n",
        "\n",
        "\n",
        "# Convert models to list of tuples (required by documentation)\n",
        "model_list = list(models_dict.items()) \n",
        "\n",
        "# Set the weights for each model as their relative performance\n",
        "bagging_weights = all_models.TestScore[:,'Mutual_Regression (scaled)'].values\n",
        "bagging_weights = bagging_weights[:4]\n",
        "\n",
        "#Initialize bagging model\n",
        "\n",
        "bagging_prediction = []\n",
        "\n",
        "for i in range(len(model_list)):\n",
        "  model_list[i][1].fit(X_train_scaled.values, y_train_scaled.values)\n",
        "  prediction = model_list[i][1].predict(X_val_scaled)\n",
        "\n",
        "  if bagging_prediction==[]:\n",
        "    bagging_prediction = prediction*bagging_weights[i]/sum(bagging_weights)\n",
        "  else:\n",
        "    bagging_prediction = bagging_prediction+prediction*bagging_weights[i]/sum(bagging_weights)\n",
        "    \n",
        "\n",
        "\n",
        "r2_score(y_val_scaled,bagging_prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3801674898817844"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3cUhB2r0adi"
      },
      "source": [
        "# Best Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1o2bay5T0gtr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "10527cfa-31ea-4033-d6a3-30c16657382b"
      },
      "source": [
        "all_models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>TrainScore</th>\n",
              "      <th>TestScore</th>\n",
              "      <th>Model</th>\n",
              "      <th>bagging_all</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model names</th>\n",
              "      <th>technique</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"11\" valign=\"top\">LinReg</th>\n",
              "      <th>Baseline</th>\n",
              "      <td>0.367663</td>\n",
              "      <td>3.712805e-01</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Scaling</th>\n",
              "      <td>0.366933</td>\n",
              "      <td>3.687549e-01</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Engineering</th>\n",
              "      <td>0.367663</td>\n",
              "      <td>3.711575e-01</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Engineering_overall</th>\n",
              "      <td>0.367663</td>\n",
              "      <td>3.711575e-01</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Selection</th>\n",
              "      <td>0.364208</td>\n",
              "      <td>3.670587e-01</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Grid_Search</th>\n",
              "      <td>0.367663</td>\n",
              "      <td>3.692270e-01</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Fa...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stacking</th>\n",
              "      <td>0.365337</td>\n",
              "      <td>-1.840233e+08</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bagging</th>\n",
              "      <td>0.367663</td>\n",
              "      <td>3.712805e-01</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bagging_all</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mutual_Regression (scaled)</th>\n",
              "      <td>0.346013</td>\n",
              "      <td>3.785107e-01</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mutual_Regression</th>\n",
              "      <td>0.344286</td>\n",
              "      <td>3.678671e-01</td>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"11\" valign=\"top\">LassoCV</th>\n",
              "      <th>Baseline</th>\n",
              "      <td>0.338874</td>\n",
              "      <td>3.487736e-01</td>\n",
              "      <td>LassoCV(alphas=None, copy_X=True, cv=None, eps...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Scaling</th>\n",
              "      <td>0.352108</td>\n",
              "      <td>3.652172e-01</td>\n",
              "      <td>LassoCV(alphas=None, copy_X=True, cv=None, eps...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Engineering</th>\n",
              "      <td>0.338874</td>\n",
              "      <td>3.487736e-01</td>\n",
              "      <td>LassoCV(alphas=None, copy_X=True, cv=None, eps...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Engineering_overall</th>\n",
              "      <td>0.338932</td>\n",
              "      <td>3.488133e-01</td>\n",
              "      <td>LassoCV(alphas=None, copy_X=True, cv=None, eps...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Selection</th>\n",
              "      <td>0.338874</td>\n",
              "      <td>3.487736e-01</td>\n",
              "      <td>LassoCV(alphas=None, copy_X=True, cv=None, eps...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Grid_Search</th>\n",
              "      <td>0.341227</td>\n",
              "      <td>3.523124e-01</td>\n",
              "      <td>LassoCV(alphas=None, copy_X=True, cv=20, eps=0...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stacking</th>\n",
              "      <td>0.338932</td>\n",
              "      <td>3.488133e-01</td>\n",
              "      <td>LassoCV(alphas=None, copy_X=True, cv=None, eps...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bagging</th>\n",
              "      <td>0.338874</td>\n",
              "      <td>3.487736e-01</td>\n",
              "      <td>LassoCV(alphas=None, copy_X=True, cv=None, eps...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bagging_all</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mutual_Regression (scaled)</th>\n",
              "      <td>0.341012</td>\n",
              "      <td>3.577166e-01</td>\n",
              "      <td>LassoCV(alphas=None, copy_X=True, cv=None, eps...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mutual_Regression</th>\n",
              "      <td>0.338597</td>\n",
              "      <td>3.507092e-01</td>\n",
              "      <td>LassoCV(alphas=None, copy_X=True, cv=None, eps...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"11\" valign=\"top\">RidgeCV</th>\n",
              "      <th>Baseline</th>\n",
              "      <td>0.366021</td>\n",
              "      <td>3.748531e-01</td>\n",
              "      <td>RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=N...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Scaling</th>\n",
              "      <td>0.365794</td>\n",
              "      <td>3.679465e-01</td>\n",
              "      <td>RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=N...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Engineering</th>\n",
              "      <td>0.366076</td>\n",
              "      <td>3.756406e-01</td>\n",
              "      <td>RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=N...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Engineering_overall</th>\n",
              "      <td>0.366076</td>\n",
              "      <td>3.756406e-01</td>\n",
              "      <td>RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=N...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Selection</th>\n",
              "      <td>0.363367</td>\n",
              "      <td>3.732763e-01</td>\n",
              "      <td>RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=N...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Grid_Search</th>\n",
              "      <td>0.366021</td>\n",
              "      <td>3.748531e-01</td>\n",
              "      <td>RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=N...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stacking</th>\n",
              "      <td>0.368001</td>\n",
              "      <td>3.797206e-01</td>\n",
              "      <td>RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=N...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bagging</th>\n",
              "      <td>0.366021</td>\n",
              "      <td>3.748531e-01</td>\n",
              "      <td>RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=N...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bagging_all</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mutual_Regression (scaled)</th>\n",
              "      <td>0.345944</td>\n",
              "      <td>3.773493e-01</td>\n",
              "      <td>RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=N...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mutual_Regression</th>\n",
              "      <td>0.344255</td>\n",
              "      <td>3.674073e-01</td>\n",
              "      <td>RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=N...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"11\" valign=\"top\">RF</th>\n",
              "      <th>Baseline</th>\n",
              "      <td>0.902733</td>\n",
              "      <td>3.397915e-01</td>\n",
              "      <td>(DecisionTreeRegressor(ccp_alpha=0.0, criterio...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Scaling</th>\n",
              "      <td>0.903476</td>\n",
              "      <td>3.422072e-01</td>\n",
              "      <td>(DecisionTreeRegressor(ccp_alpha=0.0, criterio...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Engineering</th>\n",
              "      <td>0.901118</td>\n",
              "      <td>3.499793e-01</td>\n",
              "      <td>(DecisionTreeRegressor(ccp_alpha=0.0, criterio...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Engineering_overall</th>\n",
              "      <td>0.902333</td>\n",
              "      <td>3.406457e-01</td>\n",
              "      <td>(DecisionTreeRegressor(ccp_alpha=0.0, criterio...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Selection</th>\n",
              "      <td>0.901064</td>\n",
              "      <td>3.420192e-01</td>\n",
              "      <td>(DecisionTreeRegressor(ccp_alpha=0.0, criterio...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Grid_Search</th>\n",
              "      <td>0.898089</td>\n",
              "      <td>3.191591e-01</td>\n",
              "      <td>(DecisionTreeRegressor(ccp_alpha=0.0, criterio...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stacking</th>\n",
              "      <td>0.901370</td>\n",
              "      <td>3.384086e-01</td>\n",
              "      <td>(DecisionTreeRegressor(ccp_alpha=0.0, criterio...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bagging</th>\n",
              "      <td>0.901600</td>\n",
              "      <td>3.539882e-01</td>\n",
              "      <td>(DecisionTreeRegressor(ccp_alpha=0.0, criterio...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bagging_all</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mutual_Regression (scaled)</th>\n",
              "      <td>0.877126</td>\n",
              "      <td>2.577284e-01</td>\n",
              "      <td>(DecisionTreeRegressor(ccp_alpha=0.0, criterio...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mutual_Regression</th>\n",
              "      <td>0.877738</td>\n",
              "      <td>2.482117e-01</td>\n",
              "      <td>(DecisionTreeRegressor(ccp_alpha=0.0, criterio...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"11\" valign=\"top\">CART</th>\n",
              "      <th>Baseline</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-3.464051e-01</td>\n",
              "      <td>DecisionTreeRegressor(ccp_alpha=0.0, criterion...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Scaling</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-2.607680e-01</td>\n",
              "      <td>DecisionTreeRegressor(ccp_alpha=0.0, criterion...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Engineering</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-3.179427e-01</td>\n",
              "      <td>DecisionTreeRegressor(ccp_alpha=0.0, criterion...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Engineering_overall</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.874391e-01</td>\n",
              "      <td>DecisionTreeRegressor(ccp_alpha=0.0, criterion...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_Selection</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-4.232302e-01</td>\n",
              "      <td>DecisionTreeRegressor(ccp_alpha=0.0, criterion...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Grid_Search</th>\n",
              "      <td>0.345567</td>\n",
              "      <td>3.514629e-01</td>\n",
              "      <td>DecisionTreeRegressor(ccp_alpha=0.0, criterion...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stacking</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-4.107650e-01</td>\n",
              "      <td>DecisionTreeRegressor(ccp_alpha=0.0, criterion...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bagging</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-2.709428e-01</td>\n",
              "      <td>DecisionTreeRegressor(ccp_alpha=0.0, criterion...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bagging_all</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mutual_Regression (scaled)</th>\n",
              "      <td>0.975718</td>\n",
              "      <td>-4.259826e-01</td>\n",
              "      <td>DecisionTreeRegressor(ccp_alpha=0.0, criterion...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mutual_Regression</th>\n",
              "      <td>0.976900</td>\n",
              "      <td>-6.095152e-01</td>\n",
              "      <td>DecisionTreeRegressor(ccp_alpha=0.0, criterion...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         TrainScore  ...  bagging_all\n",
              "model names technique                                ...             \n",
              "LinReg      Baseline                       0.367663  ...          NaN\n",
              "            Scaling                        0.366933  ...          NaN\n",
              "            Feature_Engineering            0.367663  ...          NaN\n",
              "            Feature_Engineering_overall    0.367663  ...          NaN\n",
              "            Feature_Selection              0.364208  ...          NaN\n",
              "            Grid_Search                    0.367663  ...          NaN\n",
              "            Stacking                       0.365337  ...          NaN\n",
              "            Bagging                        0.367663  ...          NaN\n",
              "            Bagging_all                         NaN  ...          NaN\n",
              "            Mutual_Regression (scaled)     0.346013  ...          NaN\n",
              "            Mutual_Regression              0.344286  ...          NaN\n",
              "LassoCV     Baseline                       0.338874  ...          NaN\n",
              "            Scaling                        0.352108  ...          NaN\n",
              "            Feature_Engineering            0.338874  ...          NaN\n",
              "            Feature_Engineering_overall    0.338932  ...          NaN\n",
              "            Feature_Selection              0.338874  ...          NaN\n",
              "            Grid_Search                    0.341227  ...          NaN\n",
              "            Stacking                       0.338932  ...          NaN\n",
              "            Bagging                        0.338874  ...          NaN\n",
              "            Bagging_all                         NaN  ...          NaN\n",
              "            Mutual_Regression (scaled)     0.341012  ...          NaN\n",
              "            Mutual_Regression              0.338597  ...          NaN\n",
              "RidgeCV     Baseline                       0.366021  ...          NaN\n",
              "            Scaling                        0.365794  ...          NaN\n",
              "            Feature_Engineering            0.366076  ...          NaN\n",
              "            Feature_Engineering_overall    0.366076  ...          NaN\n",
              "            Feature_Selection              0.363367  ...          NaN\n",
              "            Grid_Search                    0.366021  ...          NaN\n",
              "            Stacking                       0.368001  ...          NaN\n",
              "            Bagging                        0.366021  ...          NaN\n",
              "            Bagging_all                         NaN  ...          NaN\n",
              "            Mutual_Regression (scaled)     0.345944  ...          NaN\n",
              "            Mutual_Regression              0.344255  ...          NaN\n",
              "RF          Baseline                       0.902733  ...          NaN\n",
              "            Scaling                        0.903476  ...          NaN\n",
              "            Feature_Engineering            0.901118  ...          NaN\n",
              "            Feature_Engineering_overall    0.902333  ...          NaN\n",
              "            Feature_Selection              0.901064  ...          NaN\n",
              "            Grid_Search                    0.898089  ...          NaN\n",
              "            Stacking                       0.901370  ...          NaN\n",
              "            Bagging                        0.901600  ...          NaN\n",
              "            Bagging_all                         NaN  ...          NaN\n",
              "            Mutual_Regression (scaled)     0.877126  ...          NaN\n",
              "            Mutual_Regression              0.877738  ...          NaN\n",
              "CART        Baseline                       1.000000  ...          NaN\n",
              "            Scaling                        1.000000  ...          NaN\n",
              "            Feature_Engineering            1.000000  ...          NaN\n",
              "            Feature_Engineering_overall    1.000000  ...          NaN\n",
              "            Feature_Selection              1.000000  ...          NaN\n",
              "            Grid_Search                    0.345567  ...          NaN\n",
              "            Stacking                       1.000000  ...          NaN\n",
              "            Bagging                        1.000000  ...          NaN\n",
              "            Bagging_all                         NaN  ...          NaN\n",
              "            Mutual_Regression (scaled)     0.975718  ...          NaN\n",
              "            Mutual_Regression              0.976900  ...          NaN\n",
              "\n",
              "[55 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14dVdFyv8SuF",
        "outputId": "66cd4764-ef42-4183-ff71-b6995ab3e263"
      },
      "source": [
        "all_models['TestScore'].sort_values(ascending = False)[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model names  technique                  \n",
              "RidgeCV      Stacking                       0.379721\n",
              "LinReg       Mutual_Regression (scaled)     0.378511\n",
              "RidgeCV      Mutual_Regression (scaled)     0.377349\n",
              "             Feature_Engineering_overall    0.375641\n",
              "             Feature_Engineering            0.375641\n",
              "             Baseline                       0.374853\n",
              "             Bagging                        0.374853\n",
              "             Grid_Search                    0.374853\n",
              "             Feature_Selection              0.373276\n",
              "LinReg       Bagging                        0.371280\n",
              "Name: TestScore, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlQ4lvOq0nLb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "2acbf933-ed1b-436f-9d91-08f3facbe1c6"
      },
      "source": [
        "highest_score_idx = all_models['TestScore'].idxmax()\n",
        "\n",
        "all_models.loc[[highest_score_idx ]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>TrainScore</th>\n",
              "      <th>TestScore</th>\n",
              "      <th>Model</th>\n",
              "      <th>bagging_all</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model names</th>\n",
              "      <th>technique</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>RidgeCV</th>\n",
              "      <th>Stacking</th>\n",
              "      <td>0.368001</td>\n",
              "      <td>0.379721</td>\n",
              "      <td>RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=N...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       TrainScore  ...  bagging_all\n",
              "model names technique              ...             \n",
              "RidgeCV     Stacking     0.368001  ...          NaN\n",
              "\n",
              "[1 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oVkWGhD_KxO"
      },
      "source": [
        "# Stack top 10 best performing models\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoJFXAWpDCjU"
      },
      "source": [
        "## Not Scaled "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AoQ09ZkCvN7"
      },
      "source": [
        "'LinReg': LinearRegression(),\n",
        "      'LassoCV': LassoCV(),\n",
        "      'RidgeCV': RidgeCV(),\n",
        "      'RF': RandomForestRegressor(),\n",
        "      'CART': DecisionTreeRegressor()\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLiqFIDSAl-l"
      },
      "source": [
        "Basic Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96CDwJy278qy",
        "outputId": "0027413c-62d9-4683-a9bf-52cc13c28395"
      },
      "source": [
        "from sklearn.ensemble import StackingRegressor\n",
        "base_models = [('RIDGE', RidgeCV()),\n",
        "               ('LR', LinearRegression()),\n",
        "               ('RF', RandomForestRegressor())]\n",
        "meta_model = RidgeCV()\n",
        "stacking_model = StackingRegressor(estimators=base_models, \n",
        "                                    final_estimator=meta_model, \n",
        "                                    passthrough=True, \n",
        "                                    cv=5,\n",
        "                                    verbose=2)\n",
        "\n",
        "fit_score_single_model(stacking_model,\"stacking\", X_train, X_val, y_train, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "stacking achieved a train score of 0.454 and test score of 0.386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4539668516650039, 0.38550350045614445)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPaoJAmVC-hE"
      },
      "source": [
        "With optimal RF GridSearch params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V3Skit9C1M9",
        "outputId": "aa16f3a8-0ced-47f8-9b5b-540dc6ef6cf6"
      },
      "source": [
        "from sklearn.ensemble import StackingRegressor\n",
        "base_models = [('RIDGE', RidgeCV()),\n",
        "               ('LR', LinearRegression()),\n",
        "               ('RF', RandomForestRegressor(criterion=\"mse\",max_features=\"auto\", min_samples_leaf=30,max_depth=3,n_estimators=29))]\n",
        "meta_model = RidgeCV()\n",
        "stacking_model = StackingRegressor(estimators=base_models, \n",
        "                                    final_estimator=meta_model, \n",
        "                                    passthrough=True, \n",
        "                                    cv=5,\n",
        "                                    verbose=2)\n",
        "\n",
        "fit_score_single_model(stacking_model,\"stacking\", X_train, X_val, y_train, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "stacking achieved a train score of 0.364 and test score of 0.384\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.36416976545511337, 0.38380283637237034)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ti-6f25DAVsr"
      },
      "source": [
        "## Scaled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeeHWy4BAq5z"
      },
      "source": [
        "Basic Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgifXHTZAZB_",
        "outputId": "b4636ca2-92d3-4f90-a659-5746da370621"
      },
      "source": [
        "from sklearn.ensemble import StackingRegressor\n",
        "base_models = [('RIDGE', RidgeCV()),\n",
        "               ('LR', LinearRegression()),\n",
        "               ('RF', RandomForestRegressor())]\n",
        "meta_model = RidgeCV()\n",
        "stacking_model = StackingRegressor(estimators=base_models, \n",
        "                                    final_estimator=meta_model, \n",
        "                                    passthrough=True, \n",
        "                                    cv=5,\n",
        "                                    verbose=2)\n",
        "\n",
        "fit_score_single_model(stacking_model,\"stacking\", X_train_scaled, X_val_scaled, y_train_scaled, y_val_scaled)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "stacking achieved a train score of 0.497 and test score of 0.385\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4971500754402214, 0.3850413594253099)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHo-uJlfCL9H"
      },
      "source": [
        "## Feature Selection & Scaled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IRIC-OrAgD6",
        "outputId": "cc6f112d-71b5-4547-e850-d4c6afdff495"
      },
      "source": [
        "base_models = [('RIDGE', RidgeCV()),\n",
        "               ('LR', LinearRegression()),\n",
        "               ('RF', RandomForestRegressor(criterion=\"mse\",max_features=\"auto\", min_samples_leaf=30,max_depth=3,n_estimators=29))]\n",
        "meta_model = RidgeCV()\n",
        "stacking_model = StackingRegressor(estimators=base_models, \n",
        "                                    final_estimator=meta_model, \n",
        "                                    passthrough=True, \n",
        "                                    cv=5,\n",
        "                                    verbose=2)\n",
        "\n",
        "fit_score_single_model(stacking_model,\"stacking\", X_train_feature_selection, X_val_feature_selection, y_train_scaled,y_val_scaled)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "stacking achieved a train score of 0.365 and test score of 0.399\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3651550324407543, 0.3988692299813194)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOdrNz3sEJov"
      },
      "source": [
        "## Stacked "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEibVRUREI94",
        "outputId": "442326f7-546a-4c4e-903e-c1180dfe8dac"
      },
      "source": [
        "base_models = [('RIDGE', RidgeCV(fit_intercept=True,gcv_mode=\"eigen\",normalize=False)),\n",
        "               (\"LASSO\", LassoCV(fit_intercept=True, normalize=True,precompute=True,cv=20)),\n",
        "               ('RF', RandomForestRegressor(criterion=\"mse\",max_features=\"auto\", min_samples_leaf=30,max_depth=3,n_estimators=29))]\n",
        "\n",
        "meta_model = RidgeCV()\n",
        "stacking_model = StackingRegressor(estimators=base_models, \n",
        "                                    final_estimator=meta_model, \n",
        "                                    passthrough=True, \n",
        "                                    cv=5,\n",
        "                                    verbose=2)\n",
        "\n",
        "fit_score_single_model(stacking_model,\"stacking\",X_train_stacked, X_val_stacked, y_train, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "stacking achieved a train score of 0.366 and test score of 0.382\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.36600875173088987, 0.38196140623556885)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9G6HaX23E9Ma"
      },
      "source": [
        "## X_train_interactions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Molz1nxDF63o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a996fb48-b42b-4879-f1de-c859de897b9b"
      },
      "source": [
        "from sklearn.ensemble import StackingRegressor\n",
        "base_models = [('RIDGE', RidgeCV(fit_intercept=True,gcv_mode=\"eigen\",normalize=False)),\n",
        "               (\"LASSO\", LassoCV(fit_intercept=True, normalize=True,precompute=True,cv=20)),\n",
        "               ('RF', RandomForestRegressor(criterion=\"mse\",max_features=\"auto\", min_samples_leaf=30,max_depth=3,n_estimators=29))]\n",
        "\n",
        "meta_model = RidgeCV()\n",
        "stacking_model = StackingRegressor(estimators=base_models, \n",
        "                                    final_estimator=meta_model, \n",
        "                                    passthrough=True, \n",
        "                                    cv=5,\n",
        "                                    verbose=2)\n",
        "\n",
        "fit_score_single_model(stacking_model,\"stacking\",X_train_interactions, X_val_interactions, y_train, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.6s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "stacking achieved a train score of 0.369 and test score of 0.385\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.36904150265760477, 0.3851383625152257)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rhc8W8QuFFA7"
      },
      "source": [
        "# Optimal Parameters "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMS4W5ycJl9E"
      },
      "source": [
        "## Ridge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_YmInBqJkuP"
      },
      "source": [
        "'fit_intercept': True, 'gcv_mode': 'eigen', 'normalize': False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG2KwtqwJ5Uy"
      },
      "source": [
        "## LinReg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkdlLex_J7H3"
      },
      "source": [
        "'fit_intercept': False, 'n_jobs': 0, 'normalize': True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-bUnByvKqlM"
      },
      "source": [
        "## Lasso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QInOTQbaKptv"
      },
      "source": [
        "'fit_intercept': True, 'normalize': True, 'precompute': True,'cv': 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QfO8wHrHugg"
      },
      "source": [
        "## CART"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4imtjTlfCegy"
      },
      "source": [
        "'criterion': 'mse', 'max_features': 'auto', 'min_samples_leaf': 30,'max_depth': 4, 'max_leaf_nodes': 10, 'splitter': 'random'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdfAV6jxH2PD"
      },
      "source": [
        "## RF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4fdOiHMH4g0"
      },
      "source": [
        "'criterion': 'mse', 'min_samples_leaf': 30,'max_depth': 3, 'max_features': 'auto','n_estimators': 29"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}